"""
Module n√†y ch·ªãu tr√°ch nhi·ªám qu·∫£n l√Ω t∆∞∆°ng t√°c v·ªõi API c·ªßa Google Gemini,
bao g·ªìm c·∫£ c∆° ch·∫ø x·ª≠ l√Ω l·ªói Quota m·∫°nh m·∫Ω, v√† ƒëƒÉng k√Ω danh s√°ch tools (bao g·ªìm plugin).
"""
import os
import time
import re
import importlib.util
from pathlib import Path
import logging
import json
import urllib.request
import urllib.error

import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted
from rich.table import Table
from rich.console import Console

# Import c√°c module con m·ªôt c√°ch an to√†n
from termi_cli.tools import web_search, database, calendar_tool, email_tool, file_system_tool, shell_tool
from termi_cli.tools import instruction_tool
from termi_cli.tools import code_tool
from termi_cli.prompts import build_enhanced_instruction
from termi_cli.config import APP_DIR

_current_api_key_index = 0
_api_keys = []
_console = Console()
_last_free_tier_call_ts: float | None = None
logger = logging.getLogger(__name__)

# --- DeepSeek integration (HTTP API, OpenAI-compatible) ---

_deepseek_api_keys: list[str] = []
_current_deepseek_key_index: int = 0
_last_deepseek_call_ts: float | None = None


class DeepseekInsufficientBalance(Exception):
    """B√°o hi·ªáu DeepSeek tr·∫£ v·ªÅ l·ªói thi·∫øu credit (HTTP 402 / Insufficient Balance)."""
    pass


# --- Groq Cloud integration (HTTP OpenAI-compatible) ---

_groq_api_keys: list[str] = []
_current_groq_key_index: int = 0
_last_groq_call_ts: float | None = None


class GroqInsufficientBalance(Exception):
    """B√°o hi·ªáu Groq Cloud tr·∫£ v·ªÅ l·ªói thi·∫øu credit (HTTP 402 / Insufficient)."""
    pass


def initialize_deepseek_api_keys() -> list[str]:
    """Kh·ªüi t·∫°o danh s√°ch DeepSeek API keys t·ª´ bi·∫øn m√¥i tr∆∞·ªùng.

    Quy ∆∞·ªõc:
    - DEEPSEEK_API_KEY
    - DEEPSEEK_API_KEY_2ND, DEEPSEEK_API_KEY_3RD, ...
    """
    global _deepseek_api_keys, _current_deepseek_key_index
    _deepseek_api_keys = []
    _current_deepseek_key_index = 0

    primary = os.getenv("DEEPSEEK_API_KEY")
    if primary:
        _deepseek_api_keys.append(primary)

    i = 2
    while True:
        key_name = (
            f"DEEPSEEK_API_KEY_{i}ND" if i == 2
            else f"DEEPSEEK_API_KEY_{i}RD" if i == 3
            else f"DEEPSEEK_API_KEY_{i}TH"
        )
        backup = os.getenv(key_name)
        if not backup:
            break
        _deepseek_api_keys.append(backup)
        i += 1

    return _deepseek_api_keys


def switch_to_next_deepseek_key() -> str:
    """Chuy·ªÉn sang DeepSeek API key ti·∫øp theo v√† quay v√≤ng gi·ªëng logic Gemini."""
    global _deepseek_api_keys, _current_deepseek_key_index
    if not _deepseek_api_keys:
        initialize_deepseek_api_keys()
        if not _deepseek_api_keys:
            raise RuntimeError("No DeepSeek API key configured (DEEPSEEK_API_KEY...).")

    _current_deepseek_key_index = (_current_deepseek_key_index + 1) % len(_deepseek_api_keys)
    return f"DeepSeek key #{_current_deepseek_key_index + 1}"


def _resilient_deepseek_api_call(model_name: str, messages: list[dict]) -> dict:
    """G·ªçi DeepSeek Chat Completions v·ªõi c∆° ch·∫ø retry + xoay API key khi h·∫øt quota.

    - S·ª≠ d·ª•ng HTTP API OpenAI-compatible: https://api.deepseek.com/chat/completions
    - Khi g·∫∑p l·ªói 429 ho·∫∑c th√¥ng b√°o ch·ª©a "rate limit"/"quota":
        * N·∫øu c√≥ nhi·ªÅu key: xoay sang key k·∫ø ti·∫øp, th·ª≠ l·∫°i.
        * N·∫øu quay l·∫°i key ban ƒë·∫ßu: coi nh∆∞ h·∫øt to√†n b·ªô key, raise exception.
    - C√≥ throttle ƒë∆°n gi·∫£n d·ª±a tr√™n _last_deepseek_call_ts (t∆∞∆°ng t·ª± Gemini).
    """
    global _deepseek_api_keys, _current_deepseek_key_index, _last_deepseek_call_ts

    if not _deepseek_api_keys:
        initialize_deepseek_api_keys()
        if not _deepseek_api_keys:
            raise RuntimeError("No DeepSeek API key configured (DEEPSEEK_API_KEY...).")

    initial_index = _current_deepseek_key_index
    url = "https://api.deepseek.com/chat/completions"

    while True:
        api_key = _deepseek_api_keys[_current_deepseek_key_index]

        # Throttle ƒë∆°n gi·∫£n gi·ªØa c√°c request DeepSeek
        now = time.time()
        min_interval = 2.0
        is_pytest = "PYTEST_CURRENT_TEST" in os.environ
        if _last_deepseek_call_ts is not None and not is_pytest:
            elapsed = now - _last_deepseek_call_ts
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

        payload = {
            "model": model_name,
            "messages": messages,
            "stream": False,
        }
        data = json.dumps(payload).encode("utf-8")
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }

        req = urllib.request.Request(url, data=data, headers=headers, method="POST")

        try:
            _last_deepseek_call_ts = time.time()
            with urllib.request.urlopen(req, timeout=60) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
                return json.loads(body)

        except urllib.error.HTTPError as e:
            body = e.read().decode("utf-8", errors="ignore")
            lower = body.lower()

            # Tr∆∞·ªùng h·ª£p h·∫øt ti·ªÅn / thi·∫øu credit: raise exception ri√™ng ƒë·ªÉ layer tr√™n c√≥ th·ªÉ fallback provider.
            if e.code == 402 or "insufficient balance" in lower:
                raise DeepseekInsufficientBalance(body) from e

            is_quota_or_rate = (
                e.code == 429
                or "rate limit" in lower
                or "quota" in lower
            )

            if is_quota_or_rate and len(_deepseek_api_keys) > 1:
                _console.print(
                    f"[yellow]‚ö†Ô∏è DeepSeek quota/rate-limit error with key #{_current_deepseek_key_index + 1}. "
                    "ƒêang chuy·ªÉn sang key ti·∫øp theo...[/yellow]"
                )
                msg = switch_to_next_deepseek_key()
                if _current_deepseek_key_index == initial_index:
                    _console.print(
                        "[bold red]‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ DeepSeek API key nh∆∞ng ƒë·ªÅu g·∫∑p l·ªói quota/rate-limit.[/bold red]"
                    )
                    raise RuntimeError("All DeepSeek API keys exhausted") from e

                _console.print(f"[green]‚úÖ ƒê√£ chuy·ªÉn sang {msg}. Th·ª≠ l·∫°i...[/green]")
                continue

            # C√°c l·ªói HTTP kh√°c: log ra console v√† re-raise ƒë·ªÉ caller x·ª≠ l√Ω
            _console.print(
                f"[bold red]L·ªói HTTP khi g·ªçi DeepSeek (status={e.code}): {body}[/bold red]"
            )
            raise

        except urllib.error.URLError as e:  # bao g·ªìm l·ªói k·∫øt n·ªëi, timeout ·ªü t·∫ßng socket
            _console.print(f"[bold red]Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi DeepSeek API: {e}[/bold red]")
            raise


def initialize_groq_api_keys() -> list[str]:
    """Kh·ªüi t·∫°o danh s√°ch Groq API keys t·ª´ bi·∫øn m√¥i tr∆∞·ªùng.

    Quy ∆∞·ªõc:
    - GROQ_API_KEY
    - GROQ_API_KEY_2ND, GROQ_API_KEY_3RD, ...
    """
    global _groq_api_keys, _current_groq_key_index
    _groq_api_keys = []
    _current_groq_key_index = 0

    primary = os.getenv("GROQ_API_KEY")
    if primary:
        _groq_api_keys.append(primary)

    i = 2
    while True:
        key_name = (
            f"GROQ_API_KEY_{i}ND" if i == 2
            else f"GROQ_API_KEY_{i}RD" if i == 3
            else f"GROQ_API_KEY_{i}TH"
        )
        backup = os.getenv(key_name)
        if not backup:
            break
        _groq_api_keys.append(backup)
        i += 1

    return _groq_api_keys


def switch_to_next_groq_key() -> str:
    """Chuy·ªÉn sang Groq API key ti·∫øp theo."""
    global _groq_api_keys, _current_groq_key_index
    if not _groq_api_keys:
        initialize_groq_api_keys()
        if not _groq_api_keys:
            raise RuntimeError("No Groq API key configured (GROQ_API_KEY...).")

    _current_groq_key_index = (_current_groq_key_index + 1) % len(_groq_api_keys)
    return f"Groq key #{_current_groq_key_index + 1}"


def _resilient_groq_api_call(model_name: str, messages: list[dict]) -> dict:
    """G·ªçi Groq Chat Completions v·ªõi c∆° ch·∫ø retry + xoay API key khi h·∫øt quota.

    - S·ª≠ d·ª•ng HTTP API OpenAI-compatible: https://api.groq.com/openai/v1/chat/completions
    - Khi g·∫∑p l·ªói 429 ho·∫∑c th√¥ng b√°o ch·ª©a "rate limit"/"quota":
        * N·∫øu c√≥ nhi·ªÅu key: xoay sang key k·∫ø ti·∫øp, th·ª≠ l·∫°i.
        * N·∫øu quay l·∫°i key ban ƒë·∫ßu: coi nh∆∞ h·∫øt to√†n b·ªô key, raise exception.
    - C√≥ throttle ƒë∆°n gi·∫£n d·ª±a tr√™n _last_groq_call_ts (t∆∞∆°ng t·ª± DeepSeek).
    """
    global _groq_api_keys, _current_groq_key_index, _last_groq_call_ts

    if not _groq_api_keys:
        initialize_groq_api_keys()
        if not _groq_api_keys:
            raise RuntimeError("No Groq API key configured (GROQ_API_KEY...).")

    initial_index = _current_groq_key_index
    url = "https://api.groq.com/openai/v1/chat/completions"

    while True:
        api_key = _groq_api_keys[_current_groq_key_index]

        now = time.time()
        min_interval = 1.0
        is_pytest = "PYTEST_CURRENT_TEST" in os.environ
        if _last_groq_call_ts is not None and not is_pytest:
            elapsed = now - _last_groq_call_ts
            if elapsed < min_interval:
                time.sleep(min_interval - elapsed)

        payload = {
            "model": model_name,
            "messages": messages,
            "stream": False,
        }
        data = json.dumps(payload).encode("utf-8")
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }

        req = urllib.request.Request(url, data=data, headers=headers, method="POST")

        try:
            _last_groq_call_ts = time.time()
            with urllib.request.urlopen(req, timeout=60) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
                return json.loads(body)

        except urllib.error.HTTPError as e:
            body = e.read().decode("utf-8", errors="ignore")
            lower = body.lower()

            if e.code == 402 or ("insufficient" in lower and ("credit" in lower or "balance" in lower or "quota" in lower)):
                raise GroqInsufficientBalance(body) from e

            is_quota_or_rate = (
                e.code == 429
                or "rate limit" in lower
                or "quota" in lower
            )

            if is_quota_or_rate and len(_groq_api_keys) > 1:
                _console.print(
                    f"[yellow]‚ö†Ô∏è Groq quota/rate-limit error with key #{_current_groq_key_index + 1}. ƒêang chuy·ªÉn sang key ti·∫øp theo...[/yellow]"
                )
                msg = switch_to_next_groq_key()
                if _current_groq_key_index == initial_index:
                    _console.print(
                        "[bold red]‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ Groq API key nh∆∞ng ƒë·ªÅu g·∫∑p l·ªói quota/rate-limit.[/bold red]"
                    )
                    raise RuntimeError("All Groq API keys exhausted") from e

                _console.print(f"[green]‚úÖ ƒê√£ chuy·ªÉn sang {msg}. Th·ª≠ l·∫°i...[/green]")
                continue

            _console.print(
                f"[bold red]L·ªói HTTP khi g·ªçi Groq (status={e.code}): {body}[/bold red]"
            )
            raise

        except urllib.error.URLError as e:
            _console.print(f"[bold red]Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi Groq API: {e}[/bold red]")
            raise


def _normalize_groq_model(model_name: str) -> str:
    """Chu·∫©n ho√° t√™n model Groq khi ng∆∞·ªùi d√πng d√πng alias ti·ªán nh·ªõ.

    - ƒê·∫ßu v√†o th∆∞·ªùng c√≥ d·∫°ng "groq-<alias-ho·∫∑c-model-th·∫≠t>".
    - N·∫øu l√† alias ng·∫Øn (v√≠ d·ª•: "groq-chat"), map sang model Groq khuy·∫øn ngh·ªã.
    - N·∫øu ƒë√£ l√† t√™n model Groq ƒë·∫ßy ƒë·ªß (v√≠ d·ª•: "groq-llama-3.1-70b-versatile"), gi·ªØ nguy√™n.
    """

    raw = model_name
    if model_name.startswith("groq-"):
        raw = model_name[len("groq-"):] or model_name

    alias_map = {
        # Alias th√¢n thi·ªán cho chat t·ªïng qu√°t (d√πng model Groq khuy·∫øn ngh·ªã m·ªõi)
        "chat": "llama-3.3-70b-versatile",
        # M·ªôt s·ªë alias r√∫t g·ªçn th∆∞·ªùng g·∫∑p
        "llama-3.1-70b": "llama-3.3-70b-versatile",
        "llama3-70b": "llama-3.3-70b-versatile",
        "llama3-8b": "llama3-8b-8192",
    }

    return alias_map.get(raw, raw)


def generate_text(model_name: str, prompt: str, system_instruction: str | None = None) -> str:
    """Sinh text thu·∫ßn t·ª´ m·ªôt model, b·ªçc qua resilient_generate_content + get_response_text.

    D√πng helper n√†y thay v√¨ kh·ªüi t·∫°o genai.GenerativeModel tr·ª±c ti·∫øp ·ªü c√°c module kh√°c,
    ƒë·ªÉ sau n√†y c√≥ th·ªÉ ho√°n ƒë·ªïi provider (v√≠ d·ª• DeepSeek, Groq) ch·ªâ b·∫±ng c√°ch s·ª≠a api.py.

    - Nh√°nh ``deepseek-*``: g·ªçi DeepSeek Chat Completions qua HTTP API v·ªõi c∆° ch·∫ø
      retry + xoay API key ri√™ng (DEEPSEEK_API_KEY, DEEPSEEK_API_KEY_2ND, ...).
    - Nh√°nh ``groq-*``: g·ªçi Groq Chat Completions (OpenAI-compatible) v·ªõi b·ªô
      Groq API key ri√™ng (GROQ_API_KEY, GROQ_API_KEY_2ND, ...).
    - C√°c model c√≤n l·∫°i: d√πng Gemini nh∆∞ tr∆∞·ªõc ƒë√¢y.
    """
    if model_name.startswith("deepseek-"):
        messages: list[dict] = []
        if system_instruction:
            messages.append({"role": "system", "content": system_instruction})
        messages.append({"role": "user", "content": prompt})

        response = _resilient_deepseek_api_call(model_name, messages)
        try:
            # OpenAI-compatible schema: choices[0].message.content
            return response["choices"][0]["message"]["content"]
        except Exception:
            # N·∫øu format kh√¥ng nh∆∞ mong ƒë·ª£i, tr·∫£ body th√¥ ƒë·ªÉ debug
            return json.dumps(response, ensure_ascii=False)

    if model_name.startswith("groq-"):
        groq_model = _normalize_groq_model(model_name)
        messages: list[dict] = []
        if system_instruction:
            messages.append({"role": "system", "content": system_instruction})
        messages.append({"role": "user", "content": prompt})

        response = _resilient_groq_api_call(groq_model, messages)
        try:
            return response["choices"][0]["message"]["content"]
        except Exception:
            return json.dumps(response, ensure_ascii=False)

    # Nh√°nh m·∫∑c ƒë·ªãnh: d√πng Gemini th√¥ng qua google.generativeai
    model_kwargs = {}
    if system_instruction is not None:
        model_kwargs["system_instruction"] = system_instruction

    model = genai.GenerativeModel(model_name, **model_kwargs)
    response = resilient_generate_content(model, prompt)
    return get_response_text(response)


def _load_plugin_tools() -> dict[str, callable]:  # type: ignore[name-defined]
    """T·∫£i th√™m tools t·ª´ th∆∞ m·ª•c plugin `APP_DIR/plugins`.

    M·ªói file `.py` (kh√¥ng b·∫Øt ƒë·∫ßu b·∫±ng `_`) c√≥ th·ªÉ ƒë·ªãnh nghƒ©a bi·∫øn
    `PLUGIN_TOOLS` l√† m·ªôt dict: t√™n_tool (str) -> callable.
    C√°c key tr√πng v·ªõi core tools s·∫Ω b·ªã b·ªè qua ƒë·ªÉ tr√°nh override ng·∫ßm.
    """

    plugin_tools: dict[str, callable] = {}
    plugins_dir = Path(APP_DIR) / "plugins"
    if not plugins_dir.exists() or not plugins_dir.is_dir():
        return plugin_tools

    for path in plugins_dir.glob("*.py"):
        if path.name.startswith("_"):
            continue

        module_name = f"termi_cli_plugins.{path.stem}"
        try:
            spec = importlib.util.spec_from_file_location(module_name, path)
            if spec is None or spec.loader is None:
                logger.warning("Kh√¥ng th·ªÉ t·∫°o spec cho plugin '%s'", path)
                continue
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)  # type: ignore[assignment]

            tools_dict = getattr(module, "PLUGIN_TOOLS", None)
            if not isinstance(tools_dict, dict):
                logger.warning("Plugin '%s' kh√¥ng c√≥ dict PLUGIN_TOOLS h·ª£p l·ªá", path)
                continue
            for name, func in tools_dict.items():
                if not callable(func):
                    logger.warning("Tool '%s' trong plugin '%s' kh√¥ng callable, b·ªè qua", name, path)
                    continue
                # Kh√¥ng override core tools
                if name in plugin_tools:
                    logger.warning("Tr√πng t√™n tool plugin '%s' trong '%s', b·ªè qua", name, path)
                    continue
                plugin_tools[name] = func
                logger.info("ƒê√£ ƒëƒÉng k√Ω plugin tool '%s' t·ª´ '%s'", name, path)
        except Exception:
            # Plugin l·ªói s·∫Ω b·ªã b·ªè qua, kh√¥ng l√†m h·ªèng to√†n b·ªô CLI
            logger.exception("L·ªói khi load plugin '%s'", path)
            continue

    return plugin_tools


# √Ånh x·∫° t√™n tool t·ªõi h√†m th·ª±c thi
AVAILABLE_TOOLS = {
    web_search.search_web.__name__: web_search.search_web,
    database.get_db_schema.__name__: database.get_db_schema,
    database.run_sql_query.__name__: database.run_sql_query,
    calendar_tool.list_events.__name__: calendar_tool.list_events,
    email_tool.search_emails.__name__: email_tool.search_emails,
    instruction_tool.save_instruction.__name__: instruction_tool.save_instruction,
    code_tool.refactor_code.__name__: code_tool.refactor_code,
    code_tool.document_code.__name__: code_tool.document_code,
    file_system_tool.list_files.__name__: file_system_tool.list_files,
    file_system_tool.read_file.__name__: file_system_tool.read_file,
    file_system_tool.write_file.__name__: file_system_tool.write_file,
    file_system_tool.create_directory.__name__: file_system_tool.create_directory,
    shell_tool.execute_command.__name__: shell_tool.execute_command,
}

# H·ª£p nh·∫•t plugin tools (n·∫øu c√≥), ∆∞u ti√™n gi·ªØ nguy√™n core tools khi tr√πng t√™n
_PLUGIN_TOOLS = _load_plugin_tools()
for _name, _func in _PLUGIN_TOOLS.items():
    if _name not in AVAILABLE_TOOLS:
        AVAILABLE_TOOLS[_name] = _func


def configure_api(api_key: str):
    """C·∫•u h√¨nh API key ban ƒë·∫ßu."""
    genai.configure(api_key=api_key)


def get_available_models() -> list[str]:
    """L·∫•y danh s√°ch c√°c model name h·ªó tr·ª£ generateContent."""
    models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    return models


def list_models(console: Console):
    """Li·ªát k√™ c√°c model c√≥ s·∫µn."""
    table = Table(title="‚ú® Danh s√°ch Models Kh·∫£ D·ª•ng ‚ú®")
    table.add_column("Provider", style="green", no_wrap=True)
    table.add_column("Model Name", style="cyan", no_wrap=True)
    table.add_column("Description", style="magenta")
    console.print("ƒêang l·∫•y danh s√°ch models...")
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            provider_label = "üü¢ Gemini"
            table.add_row(provider_label, m.name, m.description)
    console.print(table)


def list_tools(console: Console):
    table = Table(title="üîß Danh s√°ch Tools (core + plugin)")
    table.add_column("T√™n tool", style="cyan", no_wrap=True)
    table.add_column("Ngu·ªìn", style="magenta", no_wrap=True)
    table.add_column("M√¥ t·∫£", style="green")

    for name in sorted(AVAILABLE_TOOLS.keys()):
        func = AVAILABLE_TOOLS[name]
        source = "plugin" if name in _PLUGIN_TOOLS else "core"
        doc = ""
        if getattr(func, "__doc__", None):
            doc = func.__doc__.strip().splitlines()[0]
        table.add_row(name, source, doc)

    console.print(table)


def start_chat_session(model_name: str, system_instruction: str = None, history: list = None, cli_help_text: str = ""):
    """Kh·ªüi t·∫°o chat session."""
    enhanced_instruction = build_enhanced_instruction(cli_help_text)
    if system_instruction:
        enhanced_instruction = f"**PRIMARY DIRECTIVE (User-defined rules):**\n{system_instruction}\n\n---\n\n{enhanced_instruction}"

    tools_config = list(AVAILABLE_TOOLS.values())

    model = genai.GenerativeModel(
        model_name,
        system_instruction=enhanced_instruction,
        tools=tools_config
    )

    chat = model.start_chat(history=history or [])
    return chat


def get_token_usage(response):
    """Tr√≠ch xu·∫•t th√¥ng tin token usage t·ª´ response."""
    try:
        if hasattr(response, 'usage_metadata'):
            usage = response.usage_metadata
            return {
                'prompt_tokens': getattr(usage, 'prompt_token_count', 0),
                'completion_tokens': getattr(usage, 'candidates_token_count', 0),
                'total_tokens': getattr(usage, 'total_token_count', 0)
            }
    except Exception:
        pass
    return None


def get_response_text(response) -> str:
    """Tr√≠ch xu·∫•t text t·ª´ m·ªôt response Gemini, an to√†n cho c·∫£ multi-part.

    - ∆Øu ti√™n ƒë·ªçc qua `candidates[].content.parts` (c√°ch ch√≠nh th·ª©c).
    - Fallback sang thu·ªôc t√≠nh `.text` cho c√°c ƒë·ªëi t∆∞·ª£ng gi·∫£ l·∫≠p trong test.
    """
    if response is None:
        return ""

    # Th·ª≠ l·∫•y t·ª´ c·∫•u tr√∫c candidates/parts tr∆∞·ªõc (multi-part, function_call, ...)
    try:
        if hasattr(response, "candidates") and response.candidates:
            parts_text = []
            for cand in response.candidates:
                content = getattr(cand, "content", None)
                if content is None:
                    continue
                for part in getattr(content, "parts", []) or []:
                    if hasattr(part, "text") and part.text:
                        parts_text.append(part.text)
            if parts_text:
                return "".join(parts_text)
    except Exception:
        # N·∫øu c√≥ l·ªói, fallback xu·ªëng d∆∞·ªõi
        pass

    # Fallback: d√πng .text cho c√°c response ƒë∆°n gi·∫£n ho·∫∑c object gi·∫£ trong test
    try:
        text_attr = response.text  # type: ignore[attr-defined]
    except Exception:
        text_attr = None

    if isinstance(text_attr, str):
        return text_attr

    return ""


def get_model_token_limit(model_name: str) -> int:
    """L·∫•y token limit c·ªßa model."""
    try:
        model_info = genai.get_model(model_name)
        if hasattr(model_info, 'input_token_limit'):
            return model_info.input_token_limit
        if 'flash' in model_name.lower():
            return 1000000
        elif 'pro' in model_name.lower():
            return 2000000
    except Exception:
        pass
    return 0

def initialize_api_keys():
    """Kh·ªüi t·∫°o danh s√°ch API keys t·ª´ .env v√† reset tr·∫°ng th√°i."""
    global _api_keys, _current_api_key_index
    _api_keys = []
    _current_api_key_index = 0
    
    primary = os.getenv("GOOGLE_API_KEY")
    if primary:
        _api_keys.append(primary)
    
    i = 2
    while True:
        key_name = f"GOOGLE_API_KEY_{i}ND" if i == 2 else f"GOOGLE_API_KEY_{i}RD" if i == 3 else f"GOOGLE_API_KEY_{i}TH"
        backup_key = os.getenv(key_name)
        if backup_key:
            _api_keys.append(backup_key)
            i += 1
        else:
            break
    
    return _api_keys

def switch_to_next_api_key():
    """H√†m n·ªôi b·ªô ƒë·ªÉ chuy·ªÉn sang API key ti·∫øp theo v√† quay v√≤ng."""
    global _current_api_key_index, _api_keys
    _current_api_key_index = (_current_api_key_index + 1) % len(_api_keys)
    new_key = _api_keys[_current_api_key_index]
    genai.configure(api_key=new_key)
    return f"Key #{_current_api_key_index + 1}"

class RPDQuotaExhausted(Exception):
    """Exception t√πy ch·ªânh ƒë·ªÉ b√°o hi·ªáu c·∫ßn t√°i t·∫°o session."""
    pass

def _resilient_api_call(api_function, *args, **kwargs):

    """
    H√†m b·ªçc "b·∫•t t·ª≠" cho m·ªçi l·ªánh g·ªçi API, t·ª± ƒë·ªông x·ª≠ l√Ω l·ªói Quota.
    """
    initial_key_index = _current_api_key_index
    max_rpm_retries = 3
    
    while True:
        rpm_retry_count = 0
        try:
            while rpm_retry_count < max_rpm_retries:
                try:
                    # Throttle client-side: lu√¥n c√°ch nhau t·ªëi thi·ªÉu ~10 gi√¢y gi·ªØa c√°c request
                    global _last_free_tier_call_ts
                    now = time.time()
                    min_interval = 10.0

                    # Khi ch·∫°y test (pytest), b·ªè qua sleep ƒë·ªÉ test kh√¥ng ch·∫≠m
                    is_pytest = "PYTEST_CURRENT_TEST" in os.environ

                    if _last_free_tier_call_ts is not None and not is_pytest:
                        elapsed = now - _last_free_tier_call_ts
                        if elapsed < min_interval:
                            wait_time = min_interval - elapsed
                            with _console.status(
                                f"[yellow]‚è≥ Throttle: ch·ªù {wait_time:.1f}s tr∆∞·ªõc khi g·ªçi Gemini...[/yellow]",
                                spinner="clock",
                            ):
                                time.sleep(wait_time)

                    _last_free_tier_call_ts = time.time()

                    return api_function(*args, **kwargs)

                except ResourceExhausted as e:
                    error_message = str(e)

                    # N·∫øu th√¥ng b√°o cho bi·∫øt ƒë√£ h·∫øt quota free tier/ng√†y, kh√¥ng n√™n retry ti·∫øp
                    if "free_tier_requests" in error_message or "daily" in error_message:
                        raise e

                    match = re.search(r"Please retry in (\d+\.\d+)s", error_message)
                    if match:
                        rpm_retry_count += 1
                        wait_time = float(match.group(1)) + 1
                        with _console.status(
                            f"[yellow]‚è≥ L·ªói t·ªëc ƒë·ªô (RPM). Ch·ªù {wait_time:.1f}s (th·ª≠ l·∫°i {rpm_retry_count}/{max_rpm_retries})...[/yellow]",
                            spinner="clock",
                        ):
                            time.sleep(wait_time)
                    else:
                        raise e
            
            raise ResourceExhausted("H·∫øt s·ªë l·∫ßn th·ª≠ l·∫°i cho l·ªói RPM. ƒêang chuy·ªÉn key.")

        except ResourceExhausted as e:
            error_message = str(e)
            # N·∫øu ƒë√£ h·∫øt quota free tier trong ng√†y / t·ªïng, kh√¥ng xoay key n·ªØa.
            if "free_tier_requests" in error_message or "daily" in error_message:
                _console.print("[bold red]‚ùå ƒê√£ h·∫øt quota free tier (Requests Per Day / free_tier_requests). H√£y th·ª≠ l·∫°i sau khi quota ƒë∆∞·ª£c reset.[/bold red]")
                raise e

            _console.print(f"[yellow]‚ö†Ô∏è G·∫∑p l·ªói Quota v·ªõi Key #{_current_api_key_index + 1}. ƒêang chuy·ªÉn sang key ti·∫øp theo...[/yellow]")
            msg = switch_to_next_api_key()

            if _current_api_key_index == initial_key_index:
                _console.print("[bold red]‚ùå ƒê√£ th·ª≠ t·∫•t c·∫£ c√°c API key nh∆∞ng ƒë·ªÅu g·∫∑p l·ªói Quota.[/bold red]")
                raise e
            
            _console.print(f"[green]‚úÖ ƒê√£ chuy·ªÉn sang {msg}. Th·ª≠ l·∫°i...[/green]")
            raise RPDQuotaExhausted("API key changed.")

        except Exception as e:
            _console.print(f"[bold red]L·ªói kh√¥ng mong mu·ªën khi g·ªçi API: {e}[/bold red]")
            raise e

def resilient_generate_content(model: genai.GenerativeModel, prompt: str):
    """H√†m g·ªçi generate_content v·ªõi c∆° ch·∫ø retry, d√πng cho Agent v√† c√°c tool."""
    return _resilient_api_call(model.generate_content, prompt)

def resilient_send_message(chat_session: genai.ChatSession, prompt):
    """H√†m g·ªçi send_message v·ªõi c∆° ch·∫ø retry, d√πng cho Agent."""
    try:
        return _resilient_api_call(chat_session.send_message, prompt)
    except RPDQuotaExhausted:
        raise

def send_message(chat_session: genai.ChatSession, prompt_parts: list):
    """H√†m send_message g·ªëc cho ch·∫ø ƒë·ªô chat th√¥ng th∆∞·ªùng (c√≥ streaming)."""
    return chat_session.send_message(prompt_parts, stream=True)