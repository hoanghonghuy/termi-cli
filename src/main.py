import os
import sys
import json
import traceback
from dotenv import load_dotenv
from rich.console import Console
from rich.markdown import Markdown
from PIL import Image
from google.api_core.exceptions import ResourceExhausted

# --- Import c√°c module ƒë√£ ƒë∆∞·ª£c t√°ch ra ---
import api
import utils
import cli
import handlers
from config import load_config

def main(provided_args=None):
    """H√†m ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô ·ª©ng d·ª•ng."""
    # --- Giai ƒëo·∫°n 1: Thi·∫øt l·∫≠p ban ƒë·∫ßu ---
    os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '0'
    os.environ['GRPC_POLL_STRATEGY'] = 'poll'
    load_dotenv()
    console = Console()
    config = load_config()

    # --- Giai ƒëo·∫°n 2: Ph√¢n t√≠ch c√∫ ph√°p l·ªánh ---
    parser = cli.create_parser()
    args = provided_args or parser.parse_args()

    cli_help_text = parser.format_help()
    args.cli_help_text = cli_help_text 

    # Ghi ƒë√® config m·∫∑c ƒë·ªãnh t·ª´ c√°c tham s·ªë ng∆∞·ªùi d√πng
    args.model = args.model or config.get("default_model")
    args.format = args.format or config.get("default_format")
    args.persona = args.persona or None

    # --- Giai ƒëo·∫°n 3: C·∫•u h√¨nh API v√† ƒëi·ªÅu ph·ªëi ---
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        console.print("[bold red]L·ªói: Vui l√≤ng thi·∫øt l·∫≠p GOOGLE_API_KEY trong file .env[/bold red]")
        return
    
    try:
        api.configure_api(api_key)

        # ƒêi·ªÅu ph·ªëi c√°c l·ªánh kh√¥ng c·∫ßn prompt
        if args.list_models:
            api.list_models(console)
            return
        if args.set_model:
            handlers.model_selection_wizard(console, config)
            return
        if args.history and not provided_args:
            selected_file = handlers.show_history_browser(console)
            if selected_file:
                new_args = parser.parse_args([]) 
                new_args.load = selected_file
                new_args.chat = True
                new_args.print_log = True
                main(new_args)
            return
        if args.document or args.refactor:
            handlers.handle_code_helper(args, config, console, cli_help_text)
            return

        # --- Giai ƒëo·∫°n 4: Chu·∫©n b·ªã v√† th·ª±c thi ---
        system_instruction = args.system_instruction or \
                             (config.get("personas", {}).get(args.persona) if args.persona else None)
        
        history = None
        load_path = None
        if args.topic:
            sanitized_topic = utils.sanitize_filename(args.topic)
            load_path = os.path.join(handlers.HISTORY_DIR, f"chat_{sanitized_topic}.json")
        elif args.load:
            load_path = args.load

        if load_path and os.path.exists(load_path):
            try:
                with open(load_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    history = data.get("history", []) if isinstance(data, dict) else data
                console.print(f"[green]ƒê√£ t·∫£i l·ªãch s·ª≠ t·ª´ '{load_path}'.[/green]")
            except Exception as e:
                console.print(f"[bold red]L·ªói khi t·∫£i l·ªãch s·ª≠: {e}[/bold red]")
                return
        
        if history and args.print_log:
            handlers.print_formatted_history(console, history)
            if not args.chat:
                return

        models_to_try = [args.model] if args.model and args.model != config.get("default_model") else config.get("model_fallback_order", [config.get("default_model")])
        
        if args.chat:
            chat_session = api.start_chat_session(models_to_try[0], system_instruction, history, cli_help_text=cli_help_text)
            handlers.run_chat_mode(chat_session, console, config, args)
            return
        
        # Logic x·ª≠ l√Ω prompt ƒë∆°n l·∫ª
        piped_input = None
        if not sys.stdin.isatty():
             piped_input = sys.stdin.read().strip()
        
        if not args.prompt and not piped_input and not args.image and not args.git_commit:
             console.print("[bold red]L·ªói: C·∫ßn cung c·∫•p prompt ho·∫∑c m·ªôt h√†nh ƒë·ªông nh∆∞ --git-commit.[/bold red]")
             parser.print_help()
             return

        prompt_parts = []
        user_question = args.prompt or ""
        if args.image:
            try:
                img = Image.open(args.image)
                prompt_parts.append(img)
            except (FileNotFoundError, IsADirectoryError):
                console.print(f"[bold red]L·ªói: Kh√¥ng t√¨m th·∫•y file ·∫£nh '{args.image}'[/bold red]")
                return
            except Exception as e:
                console.print(f"[bold red]L·ªói khi m·ªü ·∫£nh: {e}[/bold red]")
                return
        
        prompt_text = ""
        if piped_input:
            prompt_text += f"D·ª±a v√†o n·ªôi dung ƒë∆∞·ª£c cung c·∫•p sau ƒë√¢y:\n{piped_input}\n\n{user_question}"
        else:
            prompt_text += user_question

        if args.read_dir:
            console.print("[yellow]ƒêang ƒë·ªçc ng·ªØ c·∫£nh th∆∞ m·ª•c...[/yellow]")
            context = utils.get_directory_context()
            prompt_text = f"D·ª±a v√†o ng·ªØ c·∫£nh c√°c file d∆∞·ªõi ƒë√¢y:\n{context}\n\n{prompt_text}"
        
        if prompt_text:
            prompt_parts.append(prompt_text)

        response = None
        for model in models_to_try:
            try:
                if len(models_to_try) > 1:
                    console.print(f"[dim]ƒêang th·ª≠ v·ªõi model: {model}...[/dim]")
                chat_session = api.start_chat_session(model, system_instruction, history, cli_help_text=cli_help_text)
                if args.git_commit:
                    handlers.handle_git_commit(chat_session, console, args.format)
                    return
                with console.status(f"[bold green]AI (model: {model}) ƒëang suy nghƒ©...[/bold green]"):
                    response = api.send_message(chat_session, prompt_parts)
                break
            except ResourceExhausted:
                console.print(f"[bold yellow]‚ö†Ô∏è Model '{model}' ƒë√£ h·∫øt h·∫°n ng·∫°ch.[/bold yellow]")
                if model == models_to_try[-1]:
                    console.print("[bold red]‚ùå ƒê√£ th·ª≠ h·∫øt c√°c model d·ª± ph√≤ng nh∆∞ng ƒë·ªÅu th·∫•t b·∫°i.[/bold red]")
                else:
                    console.print("[cyan]ƒêang t·ª± ƒë·ªông chuy·ªÉn sang model ti·∫øp theo...[/cyan]")
                continue
            except Exception as e:
                console.print(f"[bold red]ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën v·ªõi model {model}: {e}[/bold red]")
                break
        
        if response:
            console.print("\nüí° [bold green]Ph·∫£n h·ªìi:[/bold green]")
            response_text = handlers.get_response_text(response)
            if args.output:
                try:
                    with open(args.output, 'w', encoding='utf-8') as f:
                        f.write(response_text)
                    console.print(f"[bold green]‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file: [cyan]{args.output}[/cyan][/bold green]")
                except Exception as e:
                     console.print(f"\n[bold red]L·ªói khi l∆∞u file: {e}[/bold red]")
            elif args.format == 'rich':
                console.print(Markdown(response_text))
            else:
                console.print(response_text)
                
            if response.usage_metadata:
                tokens = response.usage_metadata.total_token_count
                console.print(f"\n[dim]Token usage: {tokens}[/dim]")
            utils.execute_suggested_commands(response_text, console)

    except KeyboardInterrupt:
        console.print("\n[yellow]ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.[/yellow]")
    except Exception as e:
        console.print(f"[bold red]ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}[/bold red]")
        console.print(f"[dim]{traceback.format_exc()}[/dim]")

if __name__ == "__main__":
    main()