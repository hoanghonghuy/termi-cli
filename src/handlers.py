# src/handlers.py
import os
import sys
import json
import glob
import re
import argparse
from datetime import datetime
import subprocess
import logging

from rich.console import Console
from rich.markdown import Markdown
from rich.table import Table

# NOTE: lazy import google.generativeai (don't import at top-level to avoid native logs)
# ‚úÖ PATCH: thay v√¨ `import google.generativeai as genai` ·ªü top-level, d√πng _get_genai() ƒë·ªÉ lazy import
# (m·ªôt s·ªë ch·ªó trong file tr∆∞·ªõc ƒë√≥ d√πng genai; m√¨nh gi·ªØ logic ƒë√≥ nh∆∞ng import khi c·∫ßn)
# from google.api_core.exceptions import ResourceExhausted
from google.api_core.exceptions import ResourceExhausted

import api
import utils
from config import save_config, load_config

logger = logging.getLogger(__name__)

# --- CONSTANTS ---
HISTORY_DIR = "chat_logs"


# ---------------------------
# Utility: lazy import genai
# ---------------------------
def _get_genai():
    """
    Lazy import google.generativeai. N·∫øu kh√¥ng import ƒë∆∞·ª£c, raise ImportError.
    Gi·ªØ nguy√™n interface nh∆∞ tr∆∞·ªõc khi code g·ªëc d√πng genai.
    """
    try:
        import google.generativeai as genai  # type: ignore
        return genai
    except Exception as e:
        logger.debug("Kh√¥ng th·ªÉ import google.generativeai: %s", e, exc_info=True)
        raise ImportError("Module 'google.generativeai' ch∆∞a c√†i ho·∫∑c kh√¥ng th·ªÉ import.") from e


# ---------------------------
# HELPER FUNCTIONS
# ---------------------------
def get_response_text_from_history(history_entry):
    """Tr√≠ch xu·∫•t text t·ª´ m·ªôt entry trong ƒë·ªëi t∆∞·ª£ng history."""
    try:
        text_parts = [
            part.text
            for part in history_entry.parts
            if hasattr(part, "text") and part.text
        ]
        return "".join(text_parts)
    except Exception:
        return ""


def _sanitize_chunk_text(text: str) -> str:
    """
    Lo·∫°i b·ªè k√Ω t·ª± r√°c, CR, collapse nhi·ªÅu newline ƒë·ªÉ tr√°nh render x·∫•u.
    ‚úÖ PATCH: chu·∫©n ho√° text streaming ƒë·ªÉ tr√°nh chuy·ªán 'ch·ªØ c√°ch ch·ªØ' ho·∫∑c nhi·ªÅu d√≤ng tr·ªëng.
    """
    if not text:
        return ""
    # lo·∫°i b·ªè null bytes v√† CR
    s = text.replace("\x00", "")
    s = s.replace("\r", "")
    # collapse >3 newline th√†nh 2 newline
    while "\n\n\n\n" in s:
        s = s.replace("\n\n\n\n", "\n\n")
    while "\n\n\n" in s:
        s = s.replace("\n\n\n", "\n\n")
    # trim trailing spaces on each line
    s = "\n".join(line.rstrip() for line in s.splitlines())
    return s


def process_response_stream(response_stream, console: Console, output_format: str = "rich"):
    """
    X·ª≠ l√Ω lu·ªìng ph·∫£n h·ªìi t·ª´ AI v·ªõi format t√πy ch·ªçn.

    Gi·ªØ nguy√™n logic g·ªëc (duy·ªát chunk, l·∫•y part.text, function_call detection),
    nh∆∞ng sanitize ph·∫ßn text tr∆∞·ªõc khi in ƒë·ªÉ UI ·ªïn h∆°n.
    """
    full_text = ""
    function_calls = []

    try:
        for chunk in response_stream:
            # chunk c√≥ c·∫•u tr√∫c kh√°c nhau tu·ª≥ SDK. G·ªëc d√πng chunk.candidates[0].content.parts
            # Ch√∫ng ta c·ªë g·∫Øng t∆∞∆°ng th√≠ch nhi·ªÅu d·∫°ng:
            parts = []
            try:
                # SDK g·ªëc (c√≥ candidates)
                if hasattr(chunk, "candidates") and chunk.candidates:
                    cand0 = chunk.candidates[0]
                    # trong n·ªôi dung candidate c√≥ `content.parts`
                    content = getattr(cand0, "content", None)
                    if content and hasattr(content, "parts"):
                        parts = list(content.parts)
                # fallback: chunk c√≥ attribute .text ho·∫∑c dict-like
                if not parts:
                    if hasattr(chunk, "text"):
                        # t·∫°o pseudo-part
                        class _P:
                            def __init__(self, text): self.text = text
                        parts = [_P(getattr(chunk, "text"))]
                    elif isinstance(chunk, dict):
                        # dict c√≥ th·ªÉ ch·ª©a 'text' ho·∫∑c 'candidates'
                        if "text" in chunk and chunk["text"]:
                            class _P:
                                def __init__(self, text): self.text = text
                            parts = [_P(chunk["text"])]
                        elif "candidates" in chunk and chunk["candidates"]:
                            try:
                                cand0 = chunk["candidates"][0]
                                cont = cand0.get("content", {})
                                for p in cont.get("parts", []):
                                    class _P2:
                                        def __init__(self, text): self.text = text
                                    parts.append(_P2(p.get("text")))
                            except Exception:
                                pass
            except Exception:
                # fallback t·ªïng qu√°t: convert chunk -> str
                try:
                    txt = str(chunk)
                    class _P3:
                        def __init__(self, text): self.text = text
                    parts = [_P3(txt)]
                except Exception:
                    parts = []

            # process parts
            for part in parts:
                try:
                    part_text = getattr(part, "text", None)
                    if not part_text:
                        # n·∫øu c√≥ function_call tr√™n part
                        if hasattr(part, "function_call") and part.function_call:
                            function_calls.append(part.function_call)
                        continue
                    sanitized = _sanitize_chunk_text(part_text)
                    full_text += sanitized

                    # Render theo format (gi·ªØ h√†nh vi real-time nh∆∞ng sanitized)
                    if output_format == "rich":
                        # ‚úÖ PATCH: in t·ª´ng chunk ƒë√£ sanitize b·∫±ng Markdown (gi√∫p render code block)
                        try:
                            console.print(Markdown(sanitized), end="")
                        except Exception:
                            console.print(sanitized, end="")
                    else:
                        # Raw text: in li√™n t·ª•c
                        console.print(sanitized, end="")

                    # detect function_call attribute on part (SDK-specific)
                    if hasattr(part, 'function_call') and part.function_call:
                        function_calls.append(part.function_call)

                except Exception as ex_part:
                    logger.exception("L·ªói x·ª≠ l√Ω part trong stream: %s", ex_part)

        # cu·ªëi c√πng in 1 d√≤ng xu·ªëng ƒë·ªÉ ng·∫Øt d√≤ng n·∫øu c·∫ßn
        try:
            console.print()
        except Exception:
            pass

    except Exception as e:
        console.print(f"\n[bold red]L·ªói khi x·ª≠ l√Ω stream: {e}[/bold red]")
        logger.exception("process_response_stream error: %s", e)

    return full_text, function_calls


def print_formatted_history(console: Console, history: list):
    """In l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ t·∫£i ra m√†n h√¨nh."""
    console.print("\n--- [bold yellow]L·ªäCH S·ª¨ TR√í CHUY·ªÜN[/bold yellow] ---")
    for item in history:
        role = item.get("role", "unknown")
        text_parts = [p.get("text", "") for p in item.get("parts", []) if p.get("text")]
        text = "".join(text_parts).strip()
        if not text:
            continue
        if role == "user":
            console.print(f"\n[bold cyan]You:[/bold cyan] {text}")
        elif role == "model":
            console.print(f"\n[bold magenta]AI:[/bold magenta]")
            console.print(Markdown(text))
    console.print("\n--- [bold yellow]K·∫æT TH√öC L·ªäCH S·ª¨[/bold yellow] ---\n")


def serialize_history(history):
    """Chuy·ªÉn ƒë·ªïi history th√†nh format JSON c√≥ th·ªÉ serialize m·ªôt c√°ch an to√†n."""
    serializable = []
    for content in history:
        content_dict = {"role": getattr(content, "role", None) or content.role if hasattr(content, "role") else content.get("role", "unknown"), "parts": []}
        # support both attr-based and dict-based content
        parts_iter = getattr(content, "parts", None) or content.get("parts", []) if isinstance(content, dict) else getattr(content, "parts", [])
        for part in parts_iter:
            part_dict = {}
            # part may be object or dict
            if hasattr(part, "text") and part.text is not None:
                part_dict["text"] = part.text
            elif isinstance(part, dict) and part.get("text") is not None:
                part_dict["text"] = part.get("text")
            elif hasattr(part, "function_call") and part.function_call is not None:
                try:
                    part_dict["function_call"] = {
                        "name": part.function_call.name,
                        "args": dict(part.function_call.args) if part.function_call.args else {},
                    }
                except Exception:
                    part_dict["function_call"] = {"name": getattr(part.function_call, "name", None)}
            elif (
                hasattr(part, "function_response")
                and part.function_response is not None
            ):
                try:
                    part_dict["function_response"] = {
                        "name": part.function_response.name,
                        "response": dict(part.function_response.response) if getattr(part.function_response, "response", None) else {},
                    }
                except Exception:
                    part_dict["function_response"] = {"name": getattr(part.function_response, "name", None)}
            if part_dict:
                content_dict["parts"].append(part_dict)
        if content_dict["parts"]:
            serializable.append(content_dict)
    return serializable


def handle_conversation_turn(chat_session, prompt_parts, console: Console, model_name: str = None, output_format: str = "rich"):
    """
    X·ª≠ l√Ω m·ªôt l∆∞·ª£t h·ªôi tho·∫°i v·ªõi auto-retry khi h·∫øt quota.
    T·ª± ƒë·ªông chuy·ªÉn sang API key backup n·∫øu key hi·ªán t·∫°i h·∫øt quota.
    """
    from google.api_core.exceptions import ResourceExhausted

    max_retries = len(api._api_keys) if getattr(api, "_api_keys", None) else 1

    for attempt in range(max_retries):
        try:
            final_text_response = ""
            total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}

            # g·ªçi API - ·ªü api.send_message b·∫°n ƒë√£ implement stream / non-stream return
            response_stream = api.send_message(chat_session, prompt_parts)
            text_chunk, function_calls = process_response_stream(response_stream, console, output_format)

            # L·∫•y token usage (g·ªëc c√≥ d√πng response_stream.resolve() -> n·∫øu SDK c√≥)
            try:
                # ‚úÖ PATCH: b·ªçc try/except ƒë·ªÉ tr√°nh exception n·∫øu response_stream kh√¥ng h·ªó tr·ª£ resolve()
                if hasattr(response_stream, "resolve"):
                    try:
                        response_stream.resolve()
                    except Exception:
                        pass
                usage = {}
                try:
                    usage = api.get_token_usage(response_stream)
                except Exception:
                    usage = {}
                if usage:
                    for key in total_tokens:
                        if key in usage and usage[key]:
                            total_tokens[key] += usage[key]
            except Exception:
                # ignore usage errors
                pass

            if text_chunk:
                final_text_response += text_chunk + "\n"

            # X·ª≠ l√Ω function calls (gi·ªØ nguy√™n logic g·ªëc)
            while function_calls:
                tool_responses = []
                for func_call in function_calls:
                    tool_name = func_call.name
                    tool_args = dict(func_call.args) if func_call.args else {}

                    console.print(f"[yellow]‚öô L·ªánh g·ªçi tool: [bold]{tool_name}[/bold]({tool_args})[/yellow]")

                    if tool_name in api.AVAILABLE_TOOLS:
                        try:
                            tool_function = api.AVAILABLE_TOOLS[tool_name]
                            result = tool_function(**tool_args)

                            if tool_name in ['refactor_code', 'document_code']:
                                console.print(f"\n[bold cyan]üìÑ K·∫øt qu·∫£ t·ª´ {tool_name}:[/bold cyan]")
                                console.print(Markdown(result))
                                console.print()

                        except Exception as e:
                            result = f"Error executing tool '{tool_name}': {str(e)}"
                    else:
                        result = f"Error: Tool '{tool_name}' not found."

                    tool_responses.append({
                        "function_response": {"name": tool_name, "response": {"result": result}}
                    })

                # G·ª≠i l·∫°i tool responses nh∆∞ conversation-turn cho model
                response_stream = api.send_message(chat_session, tool_responses)
                text_chunk, function_calls = process_response_stream(response_stream, console, output_format)

                try:
                    if hasattr(response_stream, "resolve"):
                        try:
                            response_stream.resolve()
                        except Exception:
                            pass
                    usage = {}
                    try:
                        usage = api.get_token_usage(response_stream)
                    except Exception:
                        usage = {}
                    if usage:
                        for key in total_tokens:
                            if key in usage and usage[key]:
                                total_tokens[key] += usage[key]
                except Exception:
                    pass

                if text_chunk:
                    final_text_response += text_chunk + "\n"

            # L·∫•y token limit
            token_limit = 0
            if model_name:
                token_limit = api.get_model_token_limit(model_name)

            return final_text_response.strip(), total_tokens, token_limit

        except ResourceExhausted as e:
            # H·∫øt quota, th·ª≠ chuy·ªÉn sang key kh√°c
            if attempt < max_retries - 1:
                success, msg = api.switch_to_next_api_key()
                if success:
                    console.print(f"\n[yellow]‚ö† H·∫øt quota! ƒê√£ chuy·ªÉn sang API {msg}. ƒêang th·ª≠ l·∫°i...[/yellow]")
                    continue
                else:
                    console.print(f"\n[bold red]‚ùå {msg}. Kh√¥ng th·ªÉ ti·∫øp t·ª•c.[/bold red]")
                    raise
            else:
                console.print(f"\n[bold red]‚ùå ƒê√£ th·ª≠ h·∫øt {max_retries} API key(s). T·∫•t c·∫£ ƒë·ªÅu h·∫øt quota.[/bold red]")
                raise
        except Exception as e:
            # L·ªói kh√°c, kh√¥ng retry
            logger.exception("L·ªói khi x·ª≠ l√Ω conversation turn: %s", e)
            raise

    # Kh√¥ng bao gi·ªù ƒë·∫øn ƒë√¢y, nh∆∞ng ƒë·ªÉ an to√†n
    return "", {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}, 0


def model_selection_wizard(console: Console, config: dict):
    # This function remains unchanged from your original implementation
    console.print("[bold green]ƒêang l·∫•y danh s√°ch c√°c model kh·∫£ d·ª•ng...[/bold green]")
    try:
        models = api.get_available_models()
        if not models:
            console.print("[bold red]Kh√¥ng t√¨m th·∫•y model n√†o kh·∫£ d·ª•ng.[/bold red]")
            return
    except Exception as e:
        console.print(f"[bold red]L·ªói khi l·∫•y danh s√°ch model: {e}[/bold red]")
        return

    table = Table(title="Ch·ªçn m·ªôt model ƒë·ªÉ l√†m m·∫∑c ƒë·ªãnh")
    table.add_column("#", style="cyan")
    table.add_column("Model Name", style="magenta")
    stable_models = sorted([m for m in models if "preview" not in m and "exp" not in m])
    preview_models = sorted([m for m in models if "preview" in m or "exp" in m])
    sorted_models = stable_models + preview_models
    for i, model_name in enumerate(sorted_models):
        table.add_row(str(i + 1), model_name)
    console.print(table)

    while True:
        try:
            choice_str = console.input("Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa model b·∫°n mu·ªën ch·ªçn: ")
            choice = int(choice_str) - 1
            if 0 <= choice < len(sorted_models):
                selected_model = sorted_models[choice]
                config["default_model"] = selected_model
                fallback_list = [selected_model]
                for m in stable_models:
                    if m != selected_model and m not in fallback_list:
                        fallback_list.append(m)
                config["model_fallback_order"] = fallback_list
                save_config(config)
                console.print(
                    f"\n[bold green]‚úÖ ƒê√£ ƒë·∫∑t model m·∫∑c ƒë·ªãnh l√†: [cyan]{selected_model}[/cyan][/bold green]"
                )
                console.print(
                    f"[yellow]Th·ª© t·ª± model d·ª± ph√≤ng ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.[/yellow]"
                )
                break
            else:
                console.print(
                    "[bold red]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, vui l√≤ng th·ª≠ l·∫°i.[/bold red]"
                )
        except ValueError:
            console.print("[bold red]Vui l√≤ng nh·∫≠p m·ªôt con s·ªë.[/bold red]")
        except (KeyboardInterrupt, EOFError):
            console.print("\n[yellow]ƒê√£ h·ªßy l·ª±a ch·ªçn.[/yellow]")
            break


def run_chat_mode(chat_session, console: Console, config: dict, args: argparse.Namespace):
    """Ch·∫°y ch·∫ø ƒë·ªô chat t∆∞∆°ng t√°c v·ªõi logic l∆∞u tr·ªØ th√¥ng minh."""
    console.print("[bold green]ƒê√£ v√†o ch·∫ø ƒë·ªô tr√≤ chuy·ªán. G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ tho√°t.[/bold green]")
    initial_save_path = None
    if getattr(args, "topic", None):
        initial_save_path = os.path.join(HISTORY_DIR, f"chat_{utils.sanitize_filename(args.topic)}.json")
    elif getattr(args, "load", None):
        initial_save_path = args.load

    try:
        while True:
            prompt = console.input("\n[bold cyan]You:[/bold cyan] ")
            if prompt.lower().strip() in ["exit", "quit", "q"]:
                break
            if not prompt.strip():
                continue

            console.print("\n[bold magenta]AI:[/bold magenta]")
            try:
                response_text, token_usage, token_limit = handle_conversation_turn(
                    chat_session, [prompt], console,
                    model_name=config.get("default_model"),
                    output_format=getattr(args, "format", None) or config.get("default_format", "rich")
                )

                # Hi·ªÉn th·ªã token usage (n·∫øu c√≥)
                if token_usage and isinstance(token_usage, dict) and token_usage.get('total_tokens', 0) > 0:
                    if token_limit and token_limit > 0:
                        console.print(f"[dim]üìä {token_usage['total_tokens']:,} / {token_limit:,} tokens[/dim]")
                    else:
                        console.print(f"[dim]üìä {token_usage['total_tokens']:,} tokens[/dim]")
            except Exception as e:
                console.print(f"[bold red]L·ªói: {e}[/bold red]")
                logger.exception("L·ªói khi ch·∫°y v√≤ng chat: %s", e)
                continue

            # preserve original behavior: execute suggested commands if any
            utils.execute_suggested_commands(response_text, console)
    except (KeyboardInterrupt, EOFError):
        console.print("\n[yellow]ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.[/yellow]")
    finally:
        # Saving logic (gi·ªØ nguy√™n lu·ªìng g·ªëc, ch·ªâ th√™m ki·ªÉm tra an to√†n)
        if not os.path.exists(HISTORY_DIR):
            os.makedirs(HISTORY_DIR)
        save_path = initial_save_path
        title = ""
        if save_path:
            try:
                with open(save_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    title = data.get("title", os.path.basename(save_path))
            except (FileNotFoundError, json.JSONDecodeError):
                title = getattr(args, "topic", None) or os.path.splitext(os.path.basename(save_path))[0].replace("chat_", "")
        else:
            try:
                # TH√äM X·ª¨ L√ù EXCEPTION KHI TRUY C·∫¨P HISTORY
                try:
                    history_len = len(getattr(chat_session, "history", []))
                except Exception:
                    # N·∫øu kh√¥ng th·ªÉ truy c·∫≠p history (v√¨ stream ch∆∞a ho√†n th√†nh), b·ªè qua vi·ªác l∆∞u
                    console.print("\n[yellow]Kh√¥ng th·ªÉ l∆∞u l·ªãch s·ª≠ do phi√™n chat ch∆∞a ho√†n t·∫•t.[/yellow]")
                    return

                initial_len = 0
                if getattr(args, "load", None) or getattr(args, "topic", None):
                    initial_len = len(load_config().get("history", [])) or 0

                if history_len <= initial_len:
                    console.print("\n[yellow]Kh√¥ng c√≥ n·ªôi dung m·ªõi ƒë·ªÉ l∆∞u.[/yellow]")
                    return

                user_title = console.input(
                    "\n[bold yellow]L∆∞u cu·ªôc tr√≤ chuy·ªán v·ªõi t√™n (b·ªè tr·ªëng ƒë·ªÉ AI t·ª± ƒë·∫∑t t√™n): [/bold yellow]"
                ).strip()
                if user_title:
                    title = user_title
                else:
                    console.print(
                        "[cyan]AI ƒëang nghƒ© t√™n cho cu·ªôc tr√≤ chuy·ªán...[/cyan]"
                    )
                    # get_response_text_from_history expects a history entry object; guard
                    first_history_item = None
                    try:
                        first_history_item = getattr(chat_session, "history", [None])[0]
                    except Exception:
                        first_history_item = None

                    first_user_prompt = ""
                    if first_history_item:
                        try:
                            first_user_prompt = get_response_text_from_history(first_history_item)
                        except Exception:
                            try:
                                # fallback if history stored as dicts
                                hist = getattr(chat_session, "history", []) or []
                                if hist and isinstance(hist[0], dict):
                                    first_user_prompt = "".join(p.get("text","") for p in hist[0].get("parts", []))
                            except Exception:
                                first_user_prompt = ""

                    prompt_for_title = f"D·ª±a tr√™n c√¢u h·ªèi ƒë·∫ßu ti√™n n√†y: '{first_user_prompt}', h√£y t·∫°o m·ªôt ti√™u ƒë·ªÅ ng·∫Øn g·ªçn (d∆∞·ªõi 7 t·ª´) cho cu·ªôc tr√≤ chuy·ªán. Ch·ªâ tr·∫£ v·ªÅ ti√™u ƒë·ªÅ."

                    try:
                        # ‚úÖ PATCH: d√πng lazy import genai ƒë·ªÉ tr√°nh import native libs s·ªõm
                        genai = _get_genai()
                        title_chat = genai.GenerativeModel(
                            config.get("default_model")
                        ).start_chat()
                        response = title_chat.send_message(prompt_for_title)
                        # response c√≥ th·ªÉ l√† object ho·∫∑c dict
                        title = getattr(response, "text", None) or (response.get("text") if isinstance(response, dict) else str(response))
                        title = str(title).strip().replace('"', "")
                    except Exception as e:
                        logger.exception("Kh√¥ng th·ªÉ t·∫°o ti√™u ƒë·ªÅ t·ª± ƒë·ªông: %s", e)
                        title = "untitled_chat_" + datetime.now().strftime("%Y%m%d_%H%M%S")

                filename = f"chat_{utils.sanitize_filename(title)}.json"
                save_path = os.path.join(HISTORY_DIR, filename)
            except (KeyboardInterrupt, EOFError):
                console.print("\n[yellow]Kh√¥ng l∆∞u cu·ªôc tr√≤ chuy·ªán.[/yellow]")
                return
        if save_path and title:
            try:
                history_data = {
                    "title": title,
                    "last_modified": datetime.now().isoformat(),
                    "history": serialize_history(getattr(chat_session, "history", [])),
                }
                with open(save_path, "w", encoding="utf-8") as f:
                    json.dump(history_data, f, indent=2, ensure_ascii=False)
                console.print(
                    f"\n[bold yellow]L·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{save_path}'.[/bold yellow]"
                )
            except Exception as e:
                console.print(f"\n[yellow]Kh√¥ng th·ªÉ l∆∞u l·ªãch s·ª≠: {e}[/yellow]")


def show_history_browser(console: Console):
    # This function remains unchanged (kept original behavior)
    console.print(
        f"[bold green]ƒêang qu√©t c√°c file l·ªãch s·ª≠ trong `{HISTORY_DIR}/`...[/bold green]"
    )
    if not os.path.exists(HISTORY_DIR):
        console.print(
            f"[yellow]Th∆∞ m·ª•c '{HISTORY_DIR}' kh√¥ng t·ªìn t·∫°i. Ch∆∞a c√≥ l·ªãch s·ª≠ n√†o ƒë∆∞·ª£c l∆∞u.[/yellow]"
        )
        return None
    history_files = glob.glob(os.path.join(HISTORY_DIR, "*.json"))
    if not history_files:
        console.print("[yellow]Kh√¥ng t√¨m th·∫•y file l·ªãch s·ª≠ n√†o.[/yellow]")
        return None
    history_metadata = []
    for file_path in history_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                title = data.get("title", os.path.basename(file_path))
                last_modified_iso = data.get(
                    "last_modified",
                    datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                )
                history_metadata.append(
                    {
                        "title": title,
                        "last_modified": last_modified_iso,
                        "file_path": file_path,
                    }
                )
        except Exception:
            continue
    history_metadata.sort(key=lambda x: x["last_modified"], reverse=True)
    table = Table(title="üìö L·ªãch s·ª≠ Tr√≤ chuy·ªán")
    table.add_column("#", style="cyan")
    table.add_column("Ch·ªß ƒê·ªÅ Tr√≤ Chuy·ªán", style="magenta")
    table.add_column("L·∫ßn C·∫≠p Nh·∫≠t Cu·ªëi", style="green")
    for i, meta in enumerate(history_metadata):
        try:
            mod_time_str = datetime.fromisoformat(meta["last_modified"]).strftime(
                "%Y-%m-%d %H:%M:%S"
            )
        except Exception:
            mod_time_str = meta["last_modified"]
        table.add_row(str(i + 1), meta["title"], mod_time_str)
    console.print(table)
    try:
        choice_str = console.input(
            "Nh·∫≠p s·ªë ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán (nh·∫•n Enter ƒë·ªÉ tho√°t): "
        )
        if not choice_str:
            console.print("[yellow]ƒê√£ tho√°t tr√¨nh duy·ªát l·ªãch s·ª≠.[/yellow]")
            return None
        choice = int(choice_str)
        if 1 <= choice <= len(history_metadata):
            selected_file = history_metadata[choice - 1]["file_path"]
            console.print(
                f"\n[green]ƒêang t·∫£i l·∫°i cu·ªôc tr√≤ chuy·ªán: '{history_metadata[choice - 1]['title']}'...[/green]"
            )
            return selected_file
        else:
            console.print("[yellow]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá.[/yellow]")
    except (ValueError, KeyboardInterrupt, EOFError):
        console.print("\n[yellow]ƒê√£ tho√°t tr√¨nh duy·ªát l·ªãch s·ª≠.[/yellow]")
    return None


def handle_history_summary(
    console: Console, config: dict, history: list, cli_help_text: str
):
    # This function remains unchanged in behavior
    console.print(
        "\n[bold yellow]ƒêang y√™u c·∫ßu AI t√≥m t·∫Øt cu·ªôc tr√≤ chuy·ªán...[/bold yellow]"
    )
    history_text = ""
    for item in history:
        role = "User" if item.get("role") == "user" else "AI"
        text = "".join(
            p.get("text", "") for p in item.get("parts", []) if p.get("text")
        ).strip()
        if text:
            history_text += f"{role}: {text}\n"

    if not history_text:
        console.print("[yellow]L·ªãch s·ª≠ tr·ªëng, kh√¥ng c√≥ g√¨ ƒë·ªÉ t√≥m t·∫Øt.[/yellow]")
        return

    prompt = (
        "D∆∞·ªõi ƒë√¢y l√† m·ªôt cu·ªôc tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c l∆∞u. "
        "H√£y ƒë·ªçc v√† t√≥m t·∫Øt l·∫°i n·ªôi dung ch√≠nh c·ªßa n√≥ trong v√†i g·∫°ch ƒë·∫ßu d√≤ng ng·∫Øn g·ªçn.\n\n"
        f"--- N·ªòI DUNG CU·ªòC TR√í CHUY·ªÜN ---\n{history_text}---\n\n"
        "T√≥m t·∫Øt c·ªßa b·∫°n:"
    )

    try:
        model_name = config.get("default_model")
        chat_session = api.start_chat_session(
            model_name,
            "You are a helpful summarizer.",
            history=[],
            cli_help_text=cli_help_text,
        )

        console.print("\n[bold green]üìù T√≥m T·∫Øt Cu·ªôc Tr√≤ Chuy·ªán:[/bold green] ", end="")
        handle_conversation_turn(chat_session, [prompt], console)

    except Exception as e:
        console.print(f"[bold red]L·ªói khi t√≥m t·∫Øt l·ªãch s·ª≠: {e}[/bold red]")


# --- Handlers for custom instructions ---
def add_instruction(console: Console, config: dict, instruction: str):
    """Th√™m m·ªôt ch·ªâ d·∫´n m·ªõi v√†o config."""
    if "saved_instructions" not in config:
        config["saved_instructions"] = []
    if instruction not in config["saved_instructions"]:
        config["saved_instructions"].append(instruction)
        save_config(config)
        console.print(
            f"[bold green]‚úÖ ƒê√£ th√™m ch·ªâ d·∫´n m·ªõi:[/bold green] '{instruction}'"
        )
    else:
        console.print(f"[yellow]Ch·ªâ d·∫´n ƒë√£ t·ªìn t·∫°i.[/yellow]")


def list_instructions(console: Console, config: dict):
    """Li·ªát k√™ c√°c ch·ªâ d·∫´n ƒë√£ l∆∞u."""
    instructions = config.get("saved_instructions", [])
    if not instructions:
        console.print("[yellow]Kh√¥ng c√≥ ch·ªâ d·∫´n t√πy ch·ªânh n√†o ƒë∆∞·ª£c l∆∞u.[/yellow]")
        return

    table = Table(title="üìù C√°c Ch·ªâ D·∫´n T√πy Ch·ªânh ƒê√£ L∆∞u")
    table.add_column("#", style="cyan")
    table.add_column("Ch·ªâ D·∫´n", style="magenta")
    for i, instruction in enumerate(instructions):
        table.add_row(str(i + 1), instruction)
    console.print(table)


def remove_instruction(console: Console, config: dict, index: int):
    """X√≥a m·ªôt ch·ªâ d·∫´n theo index (b·∫Øt ƒë·∫ßu t·ª´ 1)."""
    instructions = config.get("saved_instructions", [])
    if not 1 <= index <= len(instructions):
        console.print(
            f"[bold red]L·ªói: Index kh√¥ng h·ª£p l·ªá. Vui l√≤ng ch·ªçn s·ªë t·ª´ 1 ƒë·∫øn {len(instructions)}.[/bold red]"
        )
        return

    removed_instruction = instructions.pop(index - 1)
    config["saved_instructions"] = instructions
    save_config(config)
    console.print(
        f"[bold green]‚úÖ ƒê√£ x√≥a ch·ªâ d·∫´n:[/bold green] '{removed_instruction}'"
    )
