Code bundle from project: cli-ai-gemini
================================================================================

DIRECTORY STRUCTURE
--------------------------------------------------------------------------------
cli-ai-gemini/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ all_code.txt
‚îú‚îÄ‚îÄ create_db.py
‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ chat_logs/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ api.py
‚îÇ   ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îú‚îÄ‚îÄ check_models.py
‚îÇ   ‚îú‚îÄ‚îÄ cli.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ handlers.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calendar_tool.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code_tool.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email_tool.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ instruction_tool.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_search.py

================================================================================

--- FILE: .gitignore ---

# M√¥i tr∆∞·ªùng ·∫£o
.venv/
venv/
env/

# File bi·∫øn m√¥i tr∆∞·ªùng
.env

# C√°c file x√°c th·ª±c nh·∫°y c·∫£m
credentials.json
token.json

# Cache c·ªßa Python
__pycache__/
*.py[cod]
*$py.class

# File database
*.db
*.sqlite3

# L·ªãch s·ª≠ tr√≤ chuy·ªán
*.json

# Th∆∞ m·ª•c c·ªßa c√°c IDE
.idea/
.vscode/

# Th∆∞ m·ª•c build v√† distribution
/dist/
/build/
*.egg-info/

================================================================================

--- FILE: create_db.py ---

# create_db.py
import sqlite3

conn = sqlite3.connect('mydatabase.db')
cursor = conn.cursor()

# Create tables
cursor.execute('''
CREATE TABLE IF NOT EXISTS users (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    email TEXT NOT NULL UNIQUE
)''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS products (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    price REAL NOT NULL
)''')

# Insert sample data (if not exists)
try:
    cursor.execute("INSERT INTO users (id, name, email) VALUES (1, 'Hoang Hong Huy', 'huy.hh@example.com')")
    cursor.execute("INSERT INTO users (id, name, email) VALUES (2, 'Nguyen Van A', 'a.nv@example.com')")
    cursor.execute("INSERT INTO products (id, name, price) VALUES (101, 'Laptop Pro', 1200.50)")
    cursor.execute("INSERT INTO products (id, name, price) VALUES (102, 'AI Mouse', 75.00)")
except sqlite3.IntegrityError:
    print("Data already exists.")

conn.commit()
conn.close()
print("Database 'mydatabase.db' created and populated successfully.")

================================================================================

--- FILE: requirements.txt ---

# requirements.txt

# Core Google AI Library (a recent, stable version)
google-generativeai==0.5.4

# Google API client for Calendar/Email
google-api-python-client==2.125.0
google-auth-httplib2==0.2.0
google-auth-oauthlib==1.2.0

# Helper libraries
python-dotenv==1.0.1
Pillow==11.3.0
ddgs==9.0.0
rich==13.7.1
SQLAlchemy==2.0.43
unidecode=1.4.0

================================================================================

--- FILE: src/__init__.py ---



================================================================================

--- FILE: src/api.py ---

# src/api.py
"""
M√¥-ƒëun n√†y ch·ªãu tr√°ch nhi·ªám qu·∫£n l√Ω t∆∞∆°ng t√°c v·ªõi API c·ªßa Google Gemini.
"""
import os
import google.generativeai as genai
from rich.table import Table
from rich.console import Console

_current_api_key_index = 0
_api_keys = []

# Import c√°c tool v√† prompt builder
from tools import web_search, database, calendar_tool, email_tool
from tools import instruction_tool
from tools import code_tool # Th√™m tool m·ªõi
from prompts import build_enhanced_instruction

# √Ånh x·∫° t√™n tool t·ªõi h√†m th·ª±c thi
AVAILABLE_TOOLS = {
    web_search.search_web.__name__: web_search.search_web,
    database.get_db_schema.__name__: database.get_db_schema,
    database.run_sql_query.__name__: database.run_sql_query,
    calendar_tool.list_events.__name__: calendar_tool.list_events,
    email_tool.search_emails.__name__: email_tool.search_emails,
    instruction_tool.save_instruction.__name__: instruction_tool.save_instruction,
    code_tool.refactor_code.__name__: code_tool.refactor_code,
    code_tool.document_code.__name__: code_tool.document_code,
}

def configure_api(api_key: str):
    """C·∫•u h√¨nh API key."""
    genai.configure(api_key=api_key)

def get_available_models() -> list[str]:
    """L·∫•y danh s√°ch c√°c model name h·ªó tr·ª£ generateContent."""
    models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    return models

def list_models(console: Console):
    """Li·ªát k√™ c√°c model c√≥ s·∫µn."""
    table = Table(title="‚ú® Danh s√°ch Models Gemini Kh·∫£ D·ª•ng ‚ú®")
    table.add_column("Model Name", style="cyan", no_wrap=True)
    table.add_column("Description", style="magenta")
    console.print("ƒêang l·∫•y danh s√°ch models...")
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            table.add_row(m.name, m.description)
    console.print(table)

def start_chat_session(model_name: str, system_instruction: str = None, history: list = None, cli_help_text: str = ""):
    """Kh·ªüi t·∫°o chat session."""
    enhanced_instruction = build_enhanced_instruction(cli_help_text)
    if system_instruction:
        enhanced_instruction = f"**PRIMARY DIRECTIVE (User-defined rules):**\n{system_instruction}\n\n---\n\n{enhanced_instruction}"

    tools_config = list(AVAILABLE_TOOLS.values())
    
    model = genai.GenerativeModel(
        model_name, 
        system_instruction=enhanced_instruction,
        tools=tools_config
    )
    chat = model.start_chat(history=history or [])
    return chat

def send_message(chat_session: genai.ChatSession, prompt_parts: list):
    """
    G·ª≠i message v√† tr·∫£ v·ªÅ m·ªôt generator ƒë·ªÉ x·ª≠ l√Ω streaming.
    """
    response = chat_session.send_message(prompt_parts, stream=True)
    return response

def get_token_usage(response):
    """Tr√≠ch xu·∫•t th√¥ng tin token usage t·ª´ response."""
    try:
        if hasattr(response, 'usage_metadata'):
            usage = response.usage_metadata
            return {
                'prompt_tokens': getattr(usage, 'prompt_token_count', 0),
                'completion_tokens': getattr(usage, 'candidates_token_count', 0),
                'total_tokens': getattr(usage, 'total_token_count', 0)
            }
    except Exception:
        pass
    return None


def get_model_token_limit(model_name: str) -> int:
    """L·∫•y token limit c·ªßa model."""
    try:
        model_info = genai.get_model(model_name)
        if hasattr(model_info, 'input_token_limit'):
            return model_info.input_token_limit
        # Fallback cho c√°c model kh√¥ng c√≥ th√¥ng tin
        if 'flash' in model_name.lower():
            return 1000000  # Flash models th∆∞·ªùng c√≥ 1M tokens
        elif 'pro' in model_name.lower():
            return 2000000  # Pro models th∆∞·ªùng c√≥ 2M tokens
    except Exception:
        pass
    return 0


def initialize_api_keys():
    """Kh·ªüi t·∫°o danh s√°ch API keys t·ª´ .env"""
    global _api_keys
    _api_keys = []
    
    primary = os.getenv("GOOGLE_API_KEY")
    if primary:
        _api_keys.append(primary)
    
    # Th√™m c√°c key backup
    i = 2
    while True:
        key_name = f"GOOGLE_API_KEY_{i}ND" if i == 2 else f"GOOGLE_API_KEY_{i}RD" if i == 3 else f"GOOGLE_API_KEY_{i}TH"
        backup_key = os.getenv(key_name)
        if backup_key:
            _api_keys.append(backup_key)
            i += 1
        else:
            break
    
    return _api_keys

def get_current_api_key():
    """L·∫•y API key hi·ªán t·∫°i"""
    global _current_api_key_index, _api_keys
    if _current_api_key_index < len(_api_keys):
        return _api_keys[_current_api_key_index]
    return None

def switch_to_next_api_key():
    """Chuy·ªÉn sang API key ti·∫øp theo"""
    global _current_api_key_index, _api_keys
    _current_api_key_index += 1
    if _current_api_key_index < len(_api_keys):
        new_key = _api_keys[_current_api_key_index]
        configure_api(new_key)
        return True, f"Key #{_current_api_key_index + 1}"
    return False, "H·∫øt API keys"

================================================================================

--- FILE: src/auth.py ---

import os.path
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

# Ph·∫°m vi quy·ªÅn m√† ta y√™u c·∫ßu
SCOPES = [
    "https://www.googleapis.com/auth/calendar",
    "https://www.googleapis.com/auth/gmail.modify"
]

def get_credentials():
    """L·∫•y credentials h·ª£p l·ªá ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi Google APIs."""
    creds = None
    if os.path.exists("token.json"):
        creds = Credentials.from_authorized_user_file("token.json", SCOPES)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                "credentials.json", SCOPES
            )
            creds = flow.run_local_server(port=0)
        
        with open("token.json", "w") as token:
            token.write(creds.to_json())
    return creds

================================================================================

--- FILE: src/check_models.py ---

import os
import google.generativeai as genai
from dotenv import load_dotenv

# T·∫£i API key
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    print("Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY trong file .env")
else:
    try:
        # C·∫•u h√¨nh
        genai.configure(api_key=api_key)

        print("ƒêang l·∫•y danh s√°ch c√°c model kh·∫£ d·ª•ng cho key c·ªßa b·∫°n...")
        print("-" * 50)

        # L·∫∑p qua t·∫•t c·∫£ model v√† ch·ªâ in ra nh·ªØng model h·ªó tr·ª£ 'generateContent'
        found_model = False
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"-> {m.name}")
                found_model = True

        if not found_model:
            print("Kh√¥ng t√¨m th·∫•y model n√†o h·ªó tr·ª£ generateContent cho API key n√†y.")

        print("-" * 50)

    except Exception as e:
        print(f"ƒê√£ x·∫£y ra l·ªói khi k·∫øt n·ªëi t·ªõi API: {e}")

================================================================================

--- FILE: src/cli.py ---

# src/cli.py

import argparse

def create_parser():
    """T·∫°o v√† c·∫•u h√¨nh parser cho c√°c tham s·ªë d√≤ng l·ªánh."""
    parser = argparse.ArgumentParser(
        description="AI Agent CLI m·∫°nh m·∫Ω v·ªõi Gemini.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    # --- C√°c ƒë·ªëi s·ªë ch√≠nh ---
    parser.add_argument("prompt", nargs='?', default=None, help="C√¢u l·ªánh h·ªèi AI.")
    parser.add_argument("--chat", action="store_true", help="B·∫≠t ch·∫ø ƒë·ªô chat t∆∞∆°ng t√°c.")
    
    # --- C·∫•u h√¨nh Model & AI ---
    parser.add_argument("--list-models", action="store_true", help="Li·ªát k√™ c√°c model kh·∫£ d·ª•ng.")
    parser.add_argument("--set-model", action="store_true", help="Ch·∫°y giao di·ªán ƒë·ªÉ ch·ªçn model m·∫∑c ƒë·ªãnh.")
    parser.add_argument("-m", "--model", type=str, help="Ch·ªçn model cho phi√™n n√†y (ghi ƒë√® t·∫°m th·ªùi).")
    parser.add_argument("-p", "--persona", type=str, help="Ch·ªçn m·ªôt persona (t√≠nh c√°ch) ƒë√£ ƒë·ªãnh nghƒ©a trong config.")
    parser.add_argument("-si", "--system-instruction", type=str, help="Ghi ƒë√® ch·ªâ d·∫´n h·ªá th·ªëng cho phi√™n n√†y.")
    
    # --- Qu·∫£n l√Ω Ch·ªâ D·∫´n T√πy Ch·ªânh ---
    instruct_group = parser.add_argument_group('Qu·∫£n l√Ω Ch·ªâ D·∫´n T√πy Ch·ªânh (Custom Instructions)')
    instruct_group.add_argument("--add-instruct", metavar="INSTRUCTION", type=str, help="Th√™m m·ªôt ch·ªâ d·∫´n l√¢u d√†i cho AI.")
    instruct_group.add_argument("--list-instructs", action="store_true", help="Li·ªát k√™ t·∫•t c·∫£ c√°c ch·ªâ d·∫´n ƒë√£ l∆∞u.")
    instruct_group.add_argument("--rm-instruct", metavar="INDEX", type=int, help="X√≥a m·ªôt ch·ªâ d·∫´n ƒë√£ l∆∞u theo s·ªë th·ª© t·ª±.")

    # --- Qu·∫£n l√Ω L·ªãch s·ª≠ ---
    parser.add_argument("--history", action="store_true", help="Hi·ªÉn th·ªã tr√¨nh duy·ªát l·ªãch s·ª≠ chat.")
    parser.add_argument("--load", type=str, help="T·∫£i l·ªãch s·ª≠ chat t·ª´ m·ªôt file c·ª• th·ªÉ.")
    parser.add_argument("--topic", type=str, help="T·∫£i ho·∫∑c t·∫°o m·ªôt cu·ªôc tr√≤ chuy·ªán theo ch·ªß ƒë·ªÅ.")
    parser.add_argument("--print-log", action="store_true", help="In n·ªôi dung c·ªßa file l·ªãch s·ª≠ ƒë√£ t·∫£i ra m√†n h√¨nh.")
    parser.add_argument("--summarize", action="store_true", help="T√≥m t·∫Øt l·ªãch s·ª≠ chat ƒë√£ t·∫£i (d√πng chung v·ªõi --load ho·∫∑c --topic).")


    # --- T√≠ch h·ª£p & Ti·ªán √≠ch Code ---
    parser.add_argument("--git-commit", action="store_true", help="T·ª± ƒë·ªông t·∫°o commit message cho c√°c thay ƒë·ªïi ƒë√£ staged.")
    parser.add_argument("--document", type=str, metavar="FILE_PATH", help="T·ª± ƒë·ªông vi·∫øt t√†i li·ªáu (docstrings) cho code trong file.")
    parser.add_argument("--refactor", type=str, metavar="FILE_PATH", help="ƒê·ªÅ xu·∫•t c√°c ph∆∞∆°ng √°n t√°i c·∫•u tr√∫c code trong file.")
    
    # --- Input & Output ---
    parser.add_argument("-i", "--image", nargs='+', type=str, help="ƒê∆∞·ªùng d·∫´n t·ªõi m·ªôt ho·∫∑c nhi·ªÅu file ·∫£nh ƒë·ªÉ ph√¢n t√≠ch.")
    parser.add_argument("-rd", "--read-dir", action="store_true", help="ƒê·ªçc ng·ªØ c·∫£nh c·ªßa to√†n b·ªô th∆∞ m·ª•c hi·ªán t·∫°i.")
    parser.add_argument("-f", "--format", type=str, choices=['rich', 'raw'], help="ƒê·ªãnh d·∫°ng output (m·∫∑c ƒë·ªãnh: rich).")
    parser.add_argument("-o", "--output", type=str, metavar="FILE_PATH", help="L∆∞u k·∫øt qu·∫£ ƒë·∫ßu ra v√†o m·ªôt file thay v√¨ in ra console.")

    return parser

================================================================================

--- FILE: src/config.py ---

import json
from pathlib import Path

CONFIG_PATH = Path("config.json")

def load_config() -> dict:
    """T·∫£i c·∫•u h√¨nh t·ª´ file config.json."""
    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except json.JSONDecodeError:
                # N·∫øu file config b·ªã l·ªói, tr·∫£ v·ªÅ c·∫•u h√¨nh m·∫∑c ƒë·ªãnh
                pass
                
    # C·∫•u h√¨nh m·∫∑c ƒë·ªãnh n·∫øu file kh√¥ng t·ªìn t·∫°i ho·∫∑c b·ªã l·ªói
    return {
        "default_model": "models/gemini-flash-latest",
        "default_format": "rich",
        "default_system_instruction": "You are a helpful AI assistant.",
        "model_fallback_order": [
            "models/gemini-flash-latest",
            "models/gemini-pro-latest"
        ],
        "personas": {},
        "database": {}
    }

def save_config(config: dict):
    """L∆∞u c·∫•u h√¨nh v√†o file config.json."""
    with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)

================================================================================

--- FILE: src/handlers.py ---

# src/handlers.py
import os
import sys
import json
import glob
import re
import argparse
from datetime import datetime
import subprocess

from rich.console import Console
from rich.markdown import Markdown
from rich.table import Table
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted

import api
import utils
from config import save_config, load_config

# --- CONSTANTS ---
HISTORY_DIR = "chat_logs"


# --- HELPER FUNCTIONS ---
def get_response_text_from_history(history_entry):
    """Tr√≠ch xu·∫•t text t·ª´ m·ªôt entry trong ƒë·ªëi t∆∞·ª£ng history."""
    try:
        text_parts = [
            part.text
            for part in history_entry.parts
            if hasattr(part, "text") and part.text
        ]
        return "".join(text_parts)
    except Exception:
        return ""


def process_response_stream(response_stream, console: Console, output_format: str = "rich"):
    """
    X·ª≠ l√Ω lu·ªìng ph·∫£n h·ªìi t·ª´ AI v·ªõi format t√πy ch·ªçn.
    """
    full_text = ""
    function_calls = []
    
    try:
        for chunk in response_stream:
            if chunk.candidates:
                for part in chunk.candidates[0].content.parts:
                    if part.text:
                        full_text += part.text
                        
                        # Render theo format
                        if output_format == "rich":
                            # Render markdown real-time
                            console.print(Markdown(part.text), end="")
                        else:
                            # Raw text
                            console.print(part.text, end="")
                            
                    if hasattr(part, 'function_call') and part.function_call:
                        function_calls.append(part.function_call)
        
        console.print()
        
    except Exception as e:
        console.print(f"\n[bold red]L·ªói khi x·ª≠ l√Ω stream: {e}[/bold red]")
    
    return full_text, function_calls


def print_formatted_history(console: Console, history: list):
    """In l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ t·∫£i ra m√†n h√¨nh."""
    console.print("\n--- [bold yellow]L·ªäCH S·ª¨ TR√í CHUY·ªÜN[/bold yellow] ---")
    for item in history:
        role = item.get("role", "unknown")
        text_parts = [p.get("text", "") for p in item.get("parts", []) if p.get("text")]
        text = "".join(text_parts).strip()
        if not text:
            continue
        if role == "user":
            console.print(f"\n[bold cyan]You:[/bold cyan] {text}")
        elif role == "model":
            console.print(f"\n[bold magenta]AI:[/bold magenta]")
            console.print(Markdown(text))
    console.print("\n--- [bold yellow]K·∫æT TH√öC L·ªäCH S·ª¨[/bold yellow] ---\n")


def serialize_history(history):
    """Chuy·ªÉn ƒë·ªïi history th√†nh format JSON c√≥ th·ªÉ serialize m·ªôt c√°ch an to√†n."""
    serializable = []
    for content in history:
        content_dict = {"role": content.role, "parts": []}
        for part in content.parts:
            part_dict = {}
            if hasattr(part, "text") and part.text is not None:
                part_dict["text"] = part.text
            elif hasattr(part, "function_call") and part.function_call is not None:
                part_dict["function_call"] = {
                    "name": part.function_call.name,
                    "args": dict(part.function_call.args),
                }
            elif (
                hasattr(part, "function_response")
                and part.function_response is not None
            ):
                part_dict["function_response"] = {
                    "name": part.function_response.name,
                    "response": dict(part.function_response.response),
                }
            if part_dict:
                content_dict["parts"].append(part_dict)
        if content_dict["parts"]:
            serializable.append(content_dict)
    return serializable


def handle_conversation_turn(chat_session, prompt_parts, console: Console, model_name: str = None, output_format: str = "rich"):
    """
    X·ª≠ l√Ω m·ªôt l∆∞·ª£t h·ªôi tho·∫°i v·ªõi auto-retry khi h·∫øt quota.
    T·ª± ƒë·ªông chuy·ªÉn sang API key backup n·∫øu key hi·ªán t·∫°i h·∫øt quota.
    """
    from google.api_core.exceptions import ResourceExhausted
    
    max_retries = len(api._api_keys) if api._api_keys else 1
    
    for attempt in range(max_retries):
        try:
            final_text_response = ""
            total_tokens = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
            
            response_stream = api.send_message(chat_session, prompt_parts)
            text_chunk, function_calls = process_response_stream(response_stream, console, output_format)
            
            # L·∫•y token usage
            try:
                response_stream.resolve()
                usage = api.get_token_usage(response_stream)
                if usage:
                    for key in total_tokens:
                        total_tokens[key] += usage[key]
            except Exception:
                pass
            
            if text_chunk:
                final_text_response += text_chunk + "\n"

            # X·ª≠ l√Ω function calls
            while function_calls:
                tool_responses = []
                for func_call in function_calls:
                    tool_name = func_call.name
                    tool_args = dict(func_call.args) if func_call.args else {}
                    
                    console.print(f"[yellow]‚öô L·ªánh g·ªçi tool: [bold]{tool_name}[/bold]({tool_args})[/yellow]")

                    if tool_name in api.AVAILABLE_TOOLS:
                        try:
                            tool_function = api.AVAILABLE_TOOLS[tool_name]
                            result = tool_function(**tool_args)
                            
                            if tool_name in ['refactor_code', 'document_code']:
                                console.print(f"\n[bold cyan]üìÑ K·∫øt qu·∫£ t·ª´ {tool_name}:[/bold cyan]")
                                console.print(Markdown(result))
                                console.print()
                                
                        except Exception as e:
                            result = f"Error executing tool '{tool_name}': {str(e)}"
                    else:
                        result = f"Error: Tool '{tool_name}' not found."
                    
                    tool_responses.append({
                        "function_response": {"name": tool_name, "response": {"result": result}}
                    })

                response_stream = api.send_message(chat_session, tool_responses)
                text_chunk, function_calls = process_response_stream(response_stream, console, output_format)
                
                try:
                    response_stream.resolve()
                    usage = api.get_token_usage(response_stream)
                    if usage:
                        for key in total_tokens:
                            total_tokens[key] += usage[key]
                except Exception:
                    pass
                
                if text_chunk:
                    final_text_response += text_chunk + "\n"
            
            # L·∫•y token limit
            token_limit = 0
            if model_name:
                token_limit = api.get_model_token_limit(model_name)
            
            return final_text_response.strip(), total_tokens, token_limit
            
        except ResourceExhausted as e:
            # H·∫øt quota, th·ª≠ chuy·ªÉn sang key kh√°c
            if attempt < max_retries - 1:
                success, msg = api.switch_to_next_api_key()
                if success:
                    console.print(f"\n[yellow]‚ö† H·∫øt quota! ƒê√£ chuy·ªÉn sang API {msg}. ƒêang th·ª≠ l·∫°i...[/yellow]")
                    continue
                else:
                    console.print(f"\n[bold red]‚ùå {msg}. Kh√¥ng th·ªÉ ti·∫øp t·ª•c.[/bold red]")
                    raise
            else:
                console.print(f"\n[bold red]‚ùå ƒê√£ th·ª≠ h·∫øt {max_retries} API key(s). T·∫•t c·∫£ ƒë·ªÅu h·∫øt quota.[/bold red]")
                raise
        except Exception as e:
            # L·ªói kh√°c, kh√¥ng retry
            raise
    
    # Kh√¥ng bao gi·ªù ƒë·∫øn ƒë√¢y, nh∆∞ng ƒë·ªÉ an to√†n
    return "", {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}, 0


def model_selection_wizard(console: Console, config: dict):
    # This function remains unchanged
    console.print("[bold green]ƒêang l·∫•y danh s√°ch c√°c model kh·∫£ d·ª•ng...[/bold green]")
    try:
        models = api.get_available_models()
        if not models:
            console.print("[bold red]Kh√¥ng t√¨m th·∫•y model n√†o kh·∫£ d·ª•ng.[/bold red]")
            return
    except Exception as e:
        console.print(f"[bold red]L·ªói khi l·∫•y danh s√°ch model: {e}[/bold red]")
        return

    table = Table(title="Ch·ªçn m·ªôt model ƒë·ªÉ l√†m m·∫∑c ƒë·ªãnh")
    table.add_column("#", style="cyan")
    table.add_column("Model Name", style="magenta")
    stable_models = sorted([m for m in models if "preview" not in m and "exp" not in m])
    preview_models = sorted([m for m in models if "preview" in m or "exp" in m])
    sorted_models = stable_models + preview_models
    for i, model_name in enumerate(sorted_models):
        table.add_row(str(i + 1), model_name)
    console.print(table)

    while True:
        try:
            choice_str = console.input("Nh·∫≠p s·ªë th·ª© t·ª± c·ªßa model b·∫°n mu·ªën ch·ªçn: ")
            choice = int(choice_str) - 1
            if 0 <= choice < len(sorted_models):
                selected_model = sorted_models[choice]
                config["default_model"] = selected_model
                fallback_list = [selected_model]
                for m in stable_models:
                    if m != selected_model and m not in fallback_list:
                        fallback_list.append(m)
                config["model_fallback_order"] = fallback_list
                save_config(config)
                console.print(
                    f"\n[bold green]‚úÖ ƒê√£ ƒë·∫∑t model m·∫∑c ƒë·ªãnh l√†: [cyan]{selected_model}[/cyan][/bold green]"
                )
                console.print(
                    f"[yellow]Th·ª© t·ª± model d·ª± ph√≤ng ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.[/yellow]"
                )
                break
            else:
                console.print(
                    "[bold red]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, vui l√≤ng th·ª≠ l·∫°i.[/bold red]"
                )
        except ValueError:
            console.print("[bold red]Vui l√≤ng nh·∫≠p m·ªôt con s·ªë.[/bold red]")
        except (KeyboardInterrupt, EOFError):
            console.print("\n[yellow]ƒê√£ h·ªßy l·ª±a ch·ªçn.[/yellow]")
            break


def run_chat_mode(chat_session, console: Console, config: dict, args: argparse.Namespace):
    """Ch·∫°y ch·∫ø ƒë·ªô chat t∆∞∆°ng t√°c v·ªõi logic l∆∞u tr·ªØ th√¥ng minh."""
    console.print("[bold green]ƒê√£ v√†o ch·∫ø ƒë·ªô tr√≤ chuy·ªán. G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ tho√°t.[/bold green]")
    initial_save_path = None
    if args.topic:
        initial_save_path = os.path.join(HISTORY_DIR, f"chat_{utils.sanitize_filename(args.topic)}.json")
    elif args.load:
        initial_save_path = args.load
        
    try:
        while True:
            prompt = console.input("\n[bold cyan]You:[/bold cyan] ")
            if prompt.lower().strip() in ["exit", "quit", "q"]: break
            if not prompt.strip(): continue

            console.print("\n[bold magenta]AI:[/bold magenta]")
            try:
                response_text, token_usage, token_limit = handle_conversation_turn(
                    chat_session, [prompt], console, 
                    model_name=config.get("default_model"),
                    output_format=config.get("default_format", "rich")
                )
                
                # Hi·ªÉn th·ªã token usage
                if token_usage and token_usage['total_tokens'] > 0:
                    if token_limit > 0:
                        console.print(f"[dim]üìä {token_usage['total_tokens']:,} / {token_limit:,} tokens[/dim]")
                    else:
                        console.print(f"[dim]üìä {token_usage['total_tokens']:,} tokens[/dim]")
            except Exception as e:
                console.print(f"[bold red]L·ªói: {e}[/bold red]")
                continue
            
            utils.execute_suggested_commands(response_text, console)
    except (KeyboardInterrupt, EOFError):
        console.print("\n[yellow]ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.[/yellow]")
    finally:
        # Saving logic
        if not os.path.exists(HISTORY_DIR):
            os.makedirs(HISTORY_DIR)
        save_path = initial_save_path
        title = ""
        if save_path:
            try:
                with open(save_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    title = data.get("title", os.path.basename(save_path))
            except (FileNotFoundError, json.JSONDecodeError):
                title = args.topic or os.path.splitext(os.path.basename(save_path))[
                    0
                ].replace("chat_", "")
        else:
            try:
                # TH√äM X·ª¨ L√ù EXCEPTION KHI TRUY C·∫¨P HISTORY
                try:
                    history_len = len(chat_session.history)
                except Exception:
                    # N·∫øu kh√¥ng th·ªÉ truy c·∫≠p history (v√¨ stream ch∆∞a ho√†n th√†nh), b·ªè qua vi·ªác l∆∞u
                    console.print("\n[yellow]Kh√¥ng th·ªÉ l∆∞u l·ªãch s·ª≠ do phi√™n chat ch∆∞a ho√†n t·∫•t.[/yellow]")
                    return
                
                initial_len = 0
                if args.load or args.topic:
                    initial_len = len(load_config().get("history", []))

                if history_len <= initial_len:
                    console.print("\n[yellow]Kh√¥ng c√≥ n·ªôi dung m·ªõi ƒë·ªÉ l∆∞u.[/yellow]")
                    return

                user_title = console.input(
                    "\n[bold yellow]L∆∞u cu·ªôc tr√≤ chuy·ªán v·ªõi t√™n (b·ªè tr·ªëng ƒë·ªÉ AI t·ª± ƒë·∫∑t t√™n): [/bold yellow]"
                ).strip()
                if user_title:
                    title = user_title
                else:
                    console.print(
                        "[cyan]AI ƒëang nghƒ© t√™n cho cu·ªôc tr√≤ chuy·ªán...[/cyan]"
                    )
                    first_user_prompt = get_response_text_from_history(
                        chat_session.history[0]
                    )
                    prompt_for_title = f"D·ª±a tr√™n c√¢u h·ªèi ƒë·∫ßu ti√™n n√†y: '{first_user_prompt}', h√£y t·∫°o m·ªôt ti√™u ƒë·ªÅ ng·∫Øn g·ªçn (d∆∞·ªõi 7 t·ª´) cho cu·ªôc tr√≤ chuy·ªán. Ch·ªâ tr·∫£ v·ªÅ ti√™u ƒë·ªÅ."

                    title_chat = genai.GenerativeModel(
                        config.get("default_model")
                    ).start_chat()
                    response = title_chat.send_message(prompt_for_title)
                    title = response.text.strip().replace('"', "")

                filename = f"chat_{utils.sanitize_filename(title)}.json"
                save_path = os.path.join(HISTORY_DIR, filename)
            except (KeyboardInterrupt, EOFError):
                console.print("\n[yellow]Kh√¥ng l∆∞u cu·ªôc tr√≤ chuy·ªán.[/yellow]")
                return
        if save_path and title:
            try:
                history_data = {
                    "title": title,
                    "last_modified": datetime.now().isoformat(),
                    "history": serialize_history(chat_session.history),
                }
                with open(save_path, "w", encoding="utf-8") as f:
                    json.dump(history_data, f, indent=2, ensure_ascii=False)
                console.print(
                    f"\n[bold yellow]L·ªãch s·ª≠ tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{save_path}'.[/bold yellow]"
                )
            except Exception as e:
                console.print(f"\n[yellow]Kh√¥ng th·ªÉ l∆∞u l·ªãch s·ª≠: {e}[/yellow]")

def show_history_browser(console: Console):
    # This function remains unchanged
    console.print(
        f"[bold green]ƒêang qu√©t c√°c file l·ªãch s·ª≠ trong `{HISTORY_DIR}/`...[/bold green]"
    )
    if not os.path.exists(HISTORY_DIR):
        console.print(
            f"[yellow]Th∆∞ m·ª•c '{HISTORY_DIR}' kh√¥ng t·ªìn t·∫°i. Ch∆∞a c√≥ l·ªãch s·ª≠ n√†o ƒë∆∞·ª£c l∆∞u.[/yellow]"
        )
        return None
    history_files = glob.glob(os.path.join(HISTORY_DIR, "*.json"))
    if not history_files:
        console.print("[yellow]Kh√¥ng t√¨m th·∫•y file l·ªãch s·ª≠ n√†o.[/yellow]")
        return None
    history_metadata = []
    for file_path in history_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                title = data.get("title", os.path.basename(file_path))
                last_modified_iso = data.get(
                    "last_modified",
                    datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                )
                history_metadata.append(
                    {
                        "title": title,
                        "last_modified": last_modified_iso,
                        "file_path": file_path,
                    }
                )
        except Exception:
            continue
    history_metadata.sort(key=lambda x: x["last_modified"], reverse=True)
    table = Table(title="üìö L·ªãch s·ª≠ Tr√≤ chuy·ªán")
    table.add_column("#", style="cyan")
    table.add_column("Ch·ªß ƒê·ªÅ Tr√≤ Chuy·ªán", style="magenta")
    table.add_column("L·∫ßn C·∫≠p Nh·∫≠t Cu·ªëi", style="green")
    for i, meta in enumerate(history_metadata):
        mod_time_str = datetime.fromisoformat(meta["last_modified"]).strftime(
            "%Y-%m-%d %H:%M:%S"
        )
        table.add_row(str(i + 1), meta["title"], mod_time_str)
    console.print(table)
    try:
        choice_str = console.input(
            "Nh·∫≠p s·ªë ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán (nh·∫•n Enter ƒë·ªÉ tho√°t): "
        )
        if not choice_str:
            console.print("[yellow]ƒê√£ tho√°t tr√¨nh duy·ªát l·ªãch s·ª≠.[/yellow]")
            return None
        choice = int(choice_str)
        if 1 <= choice <= len(history_metadata):
            selected_file = history_metadata[choice - 1]["file_path"]
            console.print(
                f"\n[green]ƒêang t·∫£i l·∫°i cu·ªôc tr√≤ chuy·ªán: '{history_metadata[choice - 1]['title']}'...[/green]"
            )
            return selected_file
        else:
            console.print("[yellow]L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá.[/yellow]")
    except (ValueError, KeyboardInterrupt, EOFError):
        console.print("\n[yellow]ƒê√£ tho√°t tr√¨nh duy·ªát l·ªãch s·ª≠.[/yellow]")
    return None


def handle_history_summary(
    console: Console, config: dict, history: list, cli_help_text: str
):
    # This function remains unchanged
    console.print(
        "\n[bold yellow]ƒêang y√™u c·∫ßu AI t√≥m t·∫Øt cu·ªôc tr√≤ chuy·ªán...[/bold yellow]"
    )
    history_text = ""
    for item in history:
        role = "User" if item.get("role") == "user" else "AI"
        text = "".join(
            p.get("text", "") for p in item.get("parts", []) if p.get("text")
        ).strip()
        if text:
            history_text += f"{role}: {text}\n"

    if not history_text:
        console.print("[yellow]L·ªãch s·ª≠ tr·ªëng, kh√¥ng c√≥ g√¨ ƒë·ªÉ t√≥m t·∫Øt.[/yellow]")
        return

    prompt = (
        "D∆∞·ªõi ƒë√¢y l√† m·ªôt cu·ªôc tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c l∆∞u. "
        "H√£y ƒë·ªçc v√† t√≥m t·∫Øt l·∫°i n·ªôi dung ch√≠nh c·ªßa n√≥ trong v√†i g·∫°ch ƒë·∫ßu d√≤ng ng·∫Øn g·ªçn.\n\n"
        f"--- N·ªòI DUNG CU·ªòC TR√í CHUY·ªÜN ---\n{history_text}---\n\n"
        "T√≥m t·∫Øt c·ªßa b·∫°n:"
    )

    try:
        model_name = config.get("default_model")
        chat_session = api.start_chat_session(
            model_name,
            "You are a helpful summarizer.",
            history=[],
            cli_help_text=cli_help_text,
        )

        console.print("\n[bold green]üìù T√≥m T·∫Øt Cu·ªôc Tr√≤ Chuy·ªán:[/bold green] ", end="")
        handle_conversation_turn(chat_session, [prompt], console)

    except Exception as e:
        console.print(f"[bold red]L·ªói khi t√≥m t·∫Øt l·ªãch s·ª≠: {e}[/bold red]")


# --- Handlers for custom instructions ---
def add_instruction(console: Console, config: dict, instruction: str):
    """Th√™m m·ªôt ch·ªâ d·∫´n m·ªõi v√†o config."""
    if "saved_instructions" not in config:
        config["saved_instructions"] = []
    if instruction not in config["saved_instructions"]:
        config["saved_instructions"].append(instruction)
        save_config(config)
        console.print(
            f"[bold green]‚úÖ ƒê√£ th√™m ch·ªâ d·∫´n m·ªõi:[/bold green] '{instruction}'"
        )
    else:
        console.print(f"[yellow]Ch·ªâ d·∫´n ƒë√£ t·ªìn t·∫°i.[/yellow]")


def list_instructions(console: Console, config: dict):
    """Li·ªát k√™ c√°c ch·ªâ d·∫´n ƒë√£ l∆∞u."""
    instructions = config.get("saved_instructions", [])
    if not instructions:
        console.print("[yellow]Kh√¥ng c√≥ ch·ªâ d·∫´n t√πy ch·ªânh n√†o ƒë∆∞·ª£c l∆∞u.[/yellow]")
        return

    table = Table(title="üìù C√°c Ch·ªâ D·∫´n T√πy Ch·ªânh ƒê√£ L∆∞u")
    table.add_column("#", style="cyan")
    table.add_column("Ch·ªâ D·∫´n", style="magenta")
    for i, instruction in enumerate(instructions):
        table.add_row(str(i + 1), instruction)
    console.print(table)


def remove_instruction(console: Console, config: dict, index: int):
    """X√≥a m·ªôt ch·ªâ d·∫´n theo index (b·∫Øt ƒë·∫ßu t·ª´ 1)."""
    instructions = config.get("saved_instructions", [])
    if not 1 <= index <= len(instructions):
        console.print(
            f"[bold red]L·ªói: Index kh√¥ng h·ª£p l·ªá. Vui l√≤ng ch·ªçn s·ªë t·ª´ 1 ƒë·∫øn {len(instructions)}.[/bold red]"
        )
        return

    removed_instruction = instructions.pop(index - 1)
    config["saved_instructions"] = instructions
    save_config(config)
    console.print(
        f"[bold green]‚úÖ ƒê√£ x√≥a ch·ªâ d·∫´n:[/bold green] '{removed_instruction}'"
    )


================================================================================

--- FILE: src/main.py ---

# src/main.py
import os
import sys

# ===== CH·∫∂N WARNING TRI·ªÜT ƒê·ªÇ =====
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '3'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '0'
os.environ['GRPC_POLL_STRATEGY'] = 'poll'

# Redirect stderr sang devnull HO√ÄN TO√ÄN
import io
_original_stderr = sys.stderr
sys.stderr = open(os.devnull, 'w')

import json
import traceback
import logging
import subprocess
from dotenv import load_dotenv
from rich.console import Console
from rich.markdown import Markdown
from PIL import Image
from google.api_core.exceptions import ResourceExhausted

import api
import utils
import cli
import handlers
from config import load_config

# T·∫Øt c√°c log kh√¥ng c·∫ßn thi·∫øt
logging.basicConfig(level=logging.ERROR)

def main(provided_args=None):
    """H√†m ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô ·ª©ng d·ª•ng."""
    load_dotenv()
    console = Console()
    config = load_config()

    parser = cli.create_parser()
    args = provided_args or parser.parse_args()

    cli_help_text = parser.format_help()
    args.cli_help_text = cli_help_text 

    args.model = args.model or config.get("default_model")
    args.format = args.format or config.get("default_format", "rich")
    args.persona = args.persona or None

    # Kh·ªüi t·∫°o API keys t·ª´ .env
    keys = api.initialize_api_keys()
    if not keys:
        console.print("[bold red]L·ªói: Vui l√≤ng thi·∫øt l·∫≠p GOOGLE_API_KEY trong file .env[/bold red]")
        return
    
    if len(keys) > 1:
        console.print(f"[dim]üîë ƒê√£ t·∫£i {len(keys)} API key(s)[/dim]")
    
    try:
        # Configure v·ªõi key ƒë·∫ßu ti√™n
        api.configure_api(keys[0])

        # X·ª≠ l√Ω c√°c l·ªánh qu·∫£n l√Ω
        if args.add_instruct:
            handlers.add_instruction(console, config, args.add_instruct)
            return
        if args.list_instructs:
            handlers.list_instructions(console, config)
            return
        if args.rm_instruct is not None:
            handlers.remove_instruction(console, config, args.rm_instruct)
            return
        
        if args.list_models:
            api.list_models(console)
            return
        if args.set_model:
            handlers.model_selection_wizard(console, config)
            return
        if args.history and not provided_args:
            selected_file = handlers.show_history_browser(console)
            if selected_file:
                prompt_text = "B·∫°n mu·ªën [c]hat ti·∫øp, [s]ummarize (t√≥m t·∫Øt), hay [q]uit? "
                action = input(prompt_text).lower()
                if action == 'c':
                    new_args = parser.parse_args(['--load', selected_file, '--chat', '--print-log'])
                    main(new_args)
                elif action == 's':
                    new_args = parser.parse_args(['--load', selected_file, '--summarize'])
                    main(new_args)
            return

        # X·ª≠ l√Ω system instruction
        saved_instructions = config.get("saved_instructions", [])
        system_instruction_str = "\n".join(f"- {item}" for item in saved_instructions)
        if args.system_instruction:
            system_instruction_str = args.system_instruction
        elif args.persona and config.get("personas", {}).get(args.persona):
            system_instruction_str = config["personas"][args.persona]
        
        # T·∫£i l·ªãch s·ª≠ n·∫øu c√≥
        history = None
        load_path = None
        if args.topic:
            sanitized_topic = utils.sanitize_filename(args.topic)
            load_path = os.path.join(handlers.HISTORY_DIR, f"chat_{sanitized_topic}.json")
        elif args.load:
            load_path = args.load

        if load_path and os.path.exists(load_path):
            try:
                with open(load_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    history = data.get("history", []) if isinstance(data, dict) else data
                console.print(f"[green]ƒê√£ t·∫£i l·ªãch s·ª≠ t·ª´ '{load_path}'.[/green]")
            except Exception as e:
                console.print(f"[bold red]L·ªói khi t·∫£i l·ªãch s·ª≠: {e}[/bold red]")
                return
        
        # X·ª≠ l√Ω summarize
        if history and args.summarize:
            handlers.handle_history_summary(console, config, history, cli_help_text)
            return
        
        # In l·ªãch s·ª≠ n·∫øu c√≥
        if history and args.print_log:
            handlers.print_formatted_history(console, history)
            if not args.chat and not args.topic:
                 return

        # Kh·ªüi t·∫°o chat session
        chat_session = api.start_chat_session(args.model, system_instruction_str, history, cli_help_text=cli_help_text)
        
        # Ch·∫ø ƒë·ªô chat
        if args.chat or args.topic:
            handlers.run_chat_mode(chat_session, console, config, args)
            return
        
        # ƒê·ªçc input t·ª´ pipe
        piped_input = None
        if not sys.stdin.isatty():
             piped_input = sys.stdin.read().strip()
        
        # Ki·ªÉm tra c√≥ prompt hay kh√¥ng
        if not any([args.prompt, piped_input, args.image, args.git_commit, args.document, args.refactor]):
             console.print("[bold red]L·ªói: C·∫ßn cung c·∫•p prompt ho·∫∑c m·ªôt h√†nh ƒë·ªông c·ª• th·ªÉ.[/bold red]")
             parser.print_help()
             return

        # X√¢y d·ª±ng prompt
        prompt_parts = []
        user_question = args.prompt or ""

        # X·ª≠ l√Ω ·∫£nh
        if args.image:
            for image_path in args.image:
                try:
                    img = Image.open(image_path)
                    prompt_parts.append(img)
                except (FileNotFoundError, IsADirectoryError):
                    console.print(f"[bold red]L·ªói: Kh√¥ng t√¨m th·∫•y file ·∫£nh '{image_path}'[/bold red]")
                    return
                except Exception as e:
                    console.print(f"[bold red]L·ªói khi m·ªü ·∫£nh '{image_path}': {e}[/bold red]")
                    return
            console.print(f"[green]ƒê√£ t·∫£i l√™n {len(args.image)} ·∫£nh.[/green]")
        
        # X√¢y d·ª±ng prompt text
        prompt_text = ""
        if piped_input:
            prompt_text += f"D·ª±a v√†o n·ªôi dung ƒë∆∞·ª£c cung c·∫•p sau ƒë√¢y:\n{piped_input}\n\n{user_question}"
        else:
            prompt_text += user_question

        # ƒê·ªçc context th∆∞ m·ª•c
        if args.read_dir:
            console.print("[yellow]ƒêang ƒë·ªçc ng·ªØ c·∫£nh th∆∞ m·ª•c...[/yellow]")
            context = utils.get_directory_context()
            prompt_text = f"D·ª±a v√†o ng·ªØ c·∫£nh c√°c file d∆∞·ªõi ƒë√¢y:\n{context}\n\n{prompt_text}"
        
        # X·ª≠ l√Ω c√°c ch·ª©c nƒÉng ƒë·∫∑c bi·ªát
        if args.git_commit:
             diff = subprocess.check_output(["git", "diff", "--staged"], text=True, encoding='utf-8')
             prompt_text = (
                 "H√£y vi·∫øt m·ªôt commit message theo chu·∫©n Conventional Commits d·ª±a tr√™n git diff sau:\n"
                 f"```diff\n{diff}\n```"
             )
        elif args.document:
            console.print(f"ü§ñ [bold cyan]ƒêang y√™u c·∫ßu AI vi·∫øt t√†i li·ªáu cho file '{args.document}'...[/bold cyan]")
            prompt_text = f"S·ª≠ d·ª•ng tool 'document_code' ƒë·ªÉ vi·∫øt t√†i li·ªáu cho file '{args.document}'."
        elif args.refactor:
            console.print(f"ü§ñ [bold cyan]ƒêang y√™u c·∫ßu AI t√°i c·∫•u tr√∫c file '{args.refactor}'...[/bold cyan]")
            prompt_text = f"S·ª≠ d·ª•ng tool 'refactor_code' ƒë·ªÉ t√°i c·∫•u tr√∫c code trong file '{args.refactor}'."

        if prompt_text:
            prompt_parts.append(prompt_text)

        # Hi·ªÉn th·ªã model ƒëang s·ª≠ d·ª•ng
        model_display_name = args.model.replace("models/", "")
        console.print(f"\n[dim]ü§ñ Model: {model_display_name}[/dim]")
        console.print("\nüí° [bold green]Ph·∫£n h·ªìi:[/bold green]")
        
        try:
            final_response_text, token_usage, token_limit = handlers.handle_conversation_turn(
                chat_session, prompt_parts, console, model_name=args.model, output_format=args.format
            )
            
            # Hi·ªÉn th·ªã token usage
            if token_usage and token_usage['total_tokens'] > 0:
                if token_limit > 0:
                    remaining = token_limit - token_usage['total_tokens']
                    console.print(f"\n[dim]üìä Token: {token_usage['prompt_tokens']} (prompt) + "
                                 f"{token_usage['completion_tokens']} (completion) = "
                                 f"{token_usage['total_tokens']:,} / {token_limit:,} "
                                 f"({remaining:,} c√≤n l·∫°i)[/dim]")
                else:
                    console.print(f"\n[dim]üìä Token: {token_usage['prompt_tokens']} (prompt) + "
                                 f"{token_usage['completion_tokens']} (completion) = "
                                 f"{token_usage['total_tokens']:,} (total)[/dim]")
            
            # L∆∞u output n·∫øu c√≥
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    f.write(final_response_text)
                console.print(f"\n[bold green]‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file: [cyan]{args.output}[/cyan][/bold green]")
            
            # Th·ª±c thi l·ªánh ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t
            utils.execute_suggested_commands(final_response_text, console)

        except ResourceExhausted:
            console.print("[bold red]‚ùå T·∫•t c·∫£ API keys ƒë·ªÅu ƒë√£ h·∫øt quota.[/bold red]")
        except Exception as e:
            console.print(f"[bold red]\nƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}[/bold red]")
            console.print(f"[dim]{traceback.format_exc()}[/dim]")

    except KeyboardInterrupt:
        console.print("\n[yellow]ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng.[/yellow]")
    except Exception as e:
        console.print(f"[bold red]ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}[/bold red]")
        console.print(f"[dim]{traceback.format_exc()}[/dim]")

if __name__ == "__main__":
    main()

================================================================================

--- FILE: src/prompts.py ---

# src/prompts.py
"""
Qu·∫£n l√Ω v√† x√¢y d·ª±ng c√°c chu·ªói prompt h·ªá th·ªëng cho AI.
Vi·ªác t√°ch prompt ra kh·ªèi logic code gi√∫p d·ªÖ d√†ng b·∫£o tr√¨, th·ª≠ nghi·ªám
v√† ch·ªânh s·ª≠a h√†nh vi c·ªßa AI m√† kh√¥ng c·∫ßn thay ƒë·ªïi c√°c file ch·ª©c nƒÉng kh√°c.
"""
from datetime import datetime

def build_enhanced_instruction(cli_help_text: str = "") -> str:
    """
    X√¢y d·ª±ng chu·ªói system instruction n√¢ng cao, cung c·∫•p cho AI nh·∫≠n th·ª©c v·ªÅ
    ng·ªØ c·∫£nh (th·ªùi gian) v√† ch√≠nh m√¥i tr∆∞·ªùng CLI c·ªßa n√≥ (self-awareness).
    """
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    instruction_template = f"""
You are a powerful AI assistant integrated into a command-line interface (CLI).
Your goal is to be as helpful as possible.

**CURRENT CONTEXT:**
- The current date and time is: {current_datetime}.

**YOUR CAPABILITIES:**

**1. Internal Tools (Function Calling):**
These are tools you can call yourself to get information or perform actions.
- `search_web(query: str)`: For real-time information (news, weather, etc.).
- `get_db_schema()`: To see database structure.
- `run_sql_query(query: str)`: To execute SELECT queries.
- `list_events(max_results: int)`: To list Google Calendar events.
- `search_emails(query: str, max_results: int)`: To search Gmail.
- `save_instruction(instruction: str)`: Use this when the user asks you to remember a rule or preference for the future. For example, if they say "Remember to always respond in Vietnamese," you should call this tool with the instruction "Always respond in Vietnamese."
- You can also analyze images provided by the user.

**2. Your Full CLI Environment (Self-Awareness):**
This is the complete `--help` output of the CLI application you are integrated into.
Use this as the **single source of truth** to answer any questions about the application's capabilities, flags, and commands.
```text
{cli_help_text}
```

**RESPONSE GUIDELINES:**
- When asked what you can do, or about your flags/commands, synthesize the information from the help text above to provide a complete and accurate answer.
- **Database Interaction Rule:** If the user asks a question about database content and you don't know the schema, your **first step must be to call `get_db_schema()`**. Do not ask the user for the schema.
- Be direct, proactive, and helpful.
"""
    return instruction_template


================================================================================

--- FILE: src/tools/__init__.py ---



================================================================================

--- FILE: src/tools/calendar_tool.py ---

import datetime
from googleapiclient.discovery import build
from auth import get_credentials

def list_events(max_results: int = 10) -> str:
    """
    Lists the next upcoming events from the user's primary Google Calendar.

    Args:
        max_results (int): The maximum number of events to return.
    """
    print("--- TOOL: ƒêang l·∫•y s·ª± ki·ªán t·ª´ L·ªãch Google ---")
    try:
        creds = get_credentials()
        service = build("calendar", "v3", credentials=creds)

        now = datetime.datetime.utcnow().isoformat() + "Z"
        events_result = (
            service.events()
            .list(
                calendarId="primary",
                timeMin=now,
                maxResults=max_results,
                singleEvents=True,
                orderBy="startTime",
            )
            .execute()
        )
        events = events_result.get("items", [])

        if not events:
            return "No upcoming events found."

        result_str = "Upcoming events:\n"
        for event in events:
            start = event["start"].get("dateTime", event["start"].get("date"))
            result_str += f"- {start}: {event['summary']}\n"
        return result_str
    except Exception as e:
        return f"An error occurred with Google Calendar: {e}"

================================================================================

--- FILE: src/tools/code_tool.py ---

# src/tools/code_tool.py
"""
C√¥ng c·ª• d√†nh cho AI ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi c√°c file code,
nh∆∞ ƒë·ªçc, t√°i c·∫•u tr√∫c, ho·∫∑c vi·∫øt t√†i li·ªáu.
"""
import google.generativeai as genai
from config import load_config

def _get_code_from_file(file_path: str) -> str | None:
    """H√†m tr·ª£ gi√∫p ƒë·ªÉ ƒë·ªçc n·ªôi dung file."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"Error: File not found at '{file_path}'"
    except Exception as e:
        return f"Error reading file: {str(e)}"

def refactor_code(file_path: str) -> str:
    """
    Ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t c√°c ph∆∞∆°ng √°n t√°i c·∫•u tr√∫c (refactor) cho code trong m·ªôt file.
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file code c·∫ßn t√°i c·∫•u tr√∫c.
    Returns:
        str: ƒêo·∫°n code ƒë√£ ƒë∆∞·ª£c t√°i c·∫•u tr√∫c ho·∫∑c c√°c ƒë·ªÅ xu·∫•t.
    """
    print(f"--- TOOL: ƒêang ƒë·ªçc file ƒë·ªÉ t√°i c·∫•u tr√∫c: {file_path} ---")
    code_content = _get_code_from_file(file_path)
    if code_content.startswith("Error"):
        return code_content

    config = load_config()
    model = genai.GenerativeModel(config.get("default_model"))
    
    prompt = (
        "V·ªõi vai tr√≤ l√† m·ªôt ki·∫øn tr√∫c s∆∞ ph·∫ßn m·ªÅm chuy√™n nghi·ªáp, h√£y t√°i c·∫•u tr√∫c (refactor) ƒëo·∫°n code d∆∞·ªõi ƒë√¢y ƒë·ªÉ n√≥ s·∫°ch h∆°n, hi·ªáu qu·∫£ h∆°n v√† d·ªÖ b·∫£o tr√¨ h∆°n.\n"
        "Ch·ªâ tr·∫£ v·ªÅ ph·∫ßn code ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong m·ªôt kh·ªëi m√£ duy nh·∫•t, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m.\n\n"
        f"```python\n{code_content}\n```"
    )
    
    print("--- TOOL: ƒêang g·ª≠i y√™u c·∫ßu t√°i c·∫•u tr√∫c t·ªõi AI ---")
    response = model.generate_content(prompt)
    return response.text

def document_code(file_path: str) -> str:
    """
    T·ª± ƒë·ªông vi·∫øt t√†i li·ªáu (docstrings, comments) cho code trong m·ªôt file.
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file code c·∫ßn vi·∫øt t√†i li·ªáu.
    Returns:
        str: ƒêo·∫°n code ƒë√£ ƒë∆∞·ª£c b·ªï sung t√†i li·ªáu.
    """
    print(f"--- TOOL: ƒêang ƒë·ªçc file ƒë·ªÉ vi·∫øt t√†i li·ªáu: {file_path} ---")
    code_content = _get_code_from_file(file_path)
    if code_content.startswith("Error"):
        return code_content

    config = load_config()
    model = genai.GenerativeModel(config.get("default_model"))
    
    prompt = (
        "V·ªõi vai tr√≤ l√† m·ªôt l·∫≠p tr√¨nh vi√™n kinh nghi·ªám, h√£y vi·∫øt t√†i li·ªáu (docstrings cho h√†m/class v√† comment cho c√°c logic ph·ª©c t·∫°p) cho ƒëo·∫°n code d∆∞·ªõi ƒë√¢y.\n"
        "H√£y tu√¢n th·ªß c√°c chu·∫©n vi·∫øt docstring ph·ªï bi·∫øn (v√≠ d·ª•: Google Style ho·∫∑c reStructuredText cho Python).\n"
        "Ch·ªâ tr·∫£ v·ªÅ ph·∫ßn code ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong m·ªôt kh·ªëi m√£ duy nh·∫•t, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m.\n\n"
        f"```python\n{code_content}\n```"
    )

    print("--- TOOL: ƒêang g·ª≠i y√™u c·∫ßu vi·∫øt t√†i li·ªáu t·ªõi AI ---")
    response = model.generate_content(prompt)
    return response.text

================================================================================

--- FILE: src/tools/database.py ---

from sqlalchemy import create_engine, inspect, text
from config import load_config

def get_db_schema() -> str:
    """
    Inspects the database and returns its schema (table names, columns, types).
    This provides context for the AI to write accurate queries.
    """
    print("--- TOOL: ƒêang l·∫•y schema c·ªßa database ---")
    try:
        config = load_config()
        db_uri = config.get("database", {}).get("connection_string")
        if not db_uri:
            return "Database connection string not configured."
        
        engine = create_engine(db_uri)
        inspector = inspect(engine)
        schema_info = []
        for table_name in inspector.get_table_names():
            columns = [f"{col['name']} ({col['type']})" for col in inspector.get_columns(table_name)]
            schema_info.append(f"Table '{table_name}': {', '.join(columns)}")
        
        # Tr·∫£ v·ªÅ th√¥ng b√°o r√µ r√†ng n·∫øu kh√¥ng c√≥ b·∫£ng
        if not schema_info:
            return "No tables found in the database."
            
        return "\n".join(schema_info)
    except Exception as e:
        return f"Error getting database schema: {e}"

def run_sql_query(query: str) -> str:
    """
    Executes a read-only SQL query (SELECT) against the database and returns the result.
    IMPORTANT: For security, only SELECT statements are allowed.
    Args:
        query (str): The SQL SELECT statement to execute.
    """
    print(f"--- TOOL: ƒêang th·ª±c thi truy v·∫•n SQL: {query} ---")
    
    if not query.strip().upper().startswith("SELECT"):
        return "Error: For security reasons, only SELECT queries are allowed."

    try:
        config = load_config()
        db_uri = config.get("database", {}).get("connection_string")
        if not db_uri:
            return "Database connection string not configured."
        
        engine = create_engine(db_uri)
        with engine.connect() as connection:
            result = connection.execute(text(query))
            rows = result.fetchall()
            if not rows:
                return "Query executed successfully, but returned no results."
            
            header = result.keys()
            result_str = " | ".join(map(str, header)) + "\n"
            result_str += "-" * (len(result_str) - 1) + "\n"
            for row in rows:
                result_str += " | ".join(map(str, row)) + "\n"
            return result_str
    except Exception as e:
        return f"Error executing SQL query: {e}"

================================================================================

--- FILE: src/tools/email_tool.py ---

from googleapiclient.discovery import build
from auth import get_credentials

def search_emails(query: str, max_results: int = 5) -> str:
    """
    Searches the user's Gmail for emails matching a query.

    Args:
        query (str): The search query (e.g., 'from:boss subject:report').
        max_results (int): The maximum number of emails to return.
    """
    print(f"--- TOOL: ƒêang t√¨m ki·∫øm Gmail v·ªõi t·ª´ kh√≥a: '{query}' ---")
    try:
        creds = get_credentials()
        service = build("gmail", "v1", credentials=creds)

        results = service.users().messages().list(userId="me", q=query, maxResults=max_results).execute()
        messages = results.get("messages", [])

        if not messages:
            return "No emails found matching the query."

        result_str = "Found emails:\n"
        for msg in messages:
            msg_data = service.users().messages().get(userId="me", id=msg["id"]).execute()
            headers = msg_data["payload"]["headers"]
            subject = next((h["value"] for h in headers if h["name"] == "Subject"), "[No Subject]")
            sender = next((h["value"] for h in headers if h["name"] == "From"), "[No Sender]")
            snippet = msg_data["snippet"]
            result_str += f"- From: {sender}\n  Subject: {subject}\n  Snippet: {snippet}\n\n"
        return result_str
    except Exception as e:
        return f"An error occurred with Gmail: {e}"

================================================================================

--- FILE: src/tools/instruction_tool.py ---

# src/tools/instruction_tool.py
"""
C√¥ng c·ª• n√†y cho ph√©p AI t·ª± qu·∫£n l√Ω danh s√°ch ch·ªâ d·∫´n t√πy ch·ªânh (custom instructions)
b·∫±ng c√°ch th√™m c√°c ch·ªâ d·∫´n m·ªõi v√†o file config.
"""

from config import load_config, save_config

def save_instruction(instruction: str) -> str:
    """
    L∆∞u m·ªôt ch·ªâ d·∫´n t√πy ch·ªânh l√¢u d√†i v√†o file config.json.
    AI n√™n s·ª≠ d·ª•ng c√¥ng c·ª• n√†y khi ng∆∞·ªùi d√πng y√™u c·∫ßu ghi nh·ªõ m·ªôt quy t·∫Øc
    ho·∫∑c s·ªü th√≠ch n√†o ƒë√≥ cho c√°c cu·ªôc tr√≤ chuy·ªán trong t∆∞∆°ng lai.

    Args:
        instruction (str): N·ªôi dung ch·ªâ d·∫´n c·∫ßn l∆∞u.

    Returns:
        str: M·ªôt th√¥ng b√°o x√°c nh·∫≠n r·∫±ng ch·ªâ d·∫´n ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng.
    """
    print(f"--- TOOL: ƒêang l∆∞u ch·ªâ d·∫´n t√πy ch·ªânh: '{instruction}' ---")
    try:
        config = load_config()
        if "saved_instructions" not in config:
            config["saved_instructions"] = []
        
        # Tr√°nh l∆∞u tr√πng l·∫∑p
        if instruction not in config["saved_instructions"]:
            config["saved_instructions"].append(instruction)
            save_config(config)
            return f"ƒê√£ l∆∞u th√†nh c√¥ng ch·ªâ d·∫´n m·ªõi: '{instruction}'"
        else:
            return f"Ch·ªâ d·∫´n '{instruction}' ƒë√£ t·ªìn t·∫°i."
            
    except Exception as e:
        return f"L·ªói khi ƒëang l∆∞u ch·ªâ d·∫´n: {str(e)}"

================================================================================

--- FILE: src/tools/web_search.py ---

import os
import time
import requests

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ theo d√µi th·ªùi gian request cu·ªëi c√πng
LAST_REQUEST_TIME = 0

def search_web(query: str):
    """
    Performs a web search using the official Brave Search API, respecting rate limits.
    Args:
        query (str): The search query to find information on the web.
    Returns:
        str: Formatted search results with titles, URLs, and snippets.
    """
    global LAST_REQUEST_TIME
    
    # --- Logic x·ª≠ l√Ω Rate Limit ---
    current_time = time.time()
    elapsed_since_last_request = current_time - LAST_REQUEST_TIME
    
    if elapsed_since_last_request < 1.0:
        sleep_duration = 1.0 - elapsed_since_last_request
        print(f"--- TOOL: Ch·ªù {sleep_duration:.2f}s ƒë·ªÉ tu√¢n th·ªß gi·ªõi h·∫°n 1 request/gi√¢y ---")
        time.sleep(sleep_duration)
    # --- K·∫øt th√∫c logic Rate Limit ---

    print(f"--- TOOL: ƒêang t√¨m ki·∫øm Brave v·ªõi t·ª´ kh√≥a: '{query}' ---")
    
    try:
        api_key = os.getenv("BRAVE_API_KEY")

        if not api_key:
            return "L·ªói: Vui l√≤ng c·∫•u h√¨nh BRAVE_API_KEY trong file .env"

        headers = {
            "Accept": "application/json",
            "X-Subscription-Token": api_key
        }
        
        params = {
            "q": query,
            "count": 5
        }

        # Th·ª±c hi·ªán request v√† c·∫≠p nh·∫≠t th·ªùi gian
        response = requests.get(
            "https://api.search.brave.com/res/v1/web/search",
            headers=headers,
            params=params,
            timeout=10
        )
        LAST_REQUEST_TIME = time.time() # C·∫≠p nh·∫≠t th·ªùi gian sau khi request ho√†n t·∫•t
        response.raise_for_status()

        search_data = response.json()
        search_items = search_data.get("web", {}).get("results", [])

        if not search_items:
            return "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o ph√π h·ª£p."

        results_str = f"T√¨m th·∫•y {len(search_items)} k·∫øt qu·∫£ cho '{query}':\n\n"
        
        for i, item in enumerate(search_items, 1):
            title = item.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
            url = item.get('url', 'Kh√¥ng c√≥ URL')
            snippet = item.get('description', 'Kh√¥ng c√≥ m√¥ t·∫£').replace('\n', ' ')
            
            results_str += f"[{i}] {title}\n"
            results_str += f"URL: {url}\n"
            results_str += f"N·ªôi dung: {snippet}\n\n"
            
        return results_str

    except requests.exceptions.RequestException as e:
        LAST_REQUEST_TIME = time.time() # C·∫≠p nh·∫≠t th·ªùi gian ngay c·∫£ khi c√≥ l·ªói
        error_msg = f"L·ªói m·∫°ng khi g·ªçi Brave API: {str(e)}"
        print(error_msg)
        return error_msg
    except Exception as e:
        LAST_REQUEST_TIME = time.time() # C·∫≠p nh·∫≠t th·ªùi gian ngay c·∫£ khi c√≥ l·ªói
        error_msg = f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t√¨m ki·∫øm: {str(e)}"
        print(error_msg)
        return error_msg

================================================================================

--- FILE: src/utils.py ---

# src/utils.py

import os
import re
import time
import subprocess
from rich.console import Console
from rich.markdown import Markdown
from unidecode import unidecode

ALLOWED_EXTENSIONS = {'.py', '.js', '.ts', '.html', '.css', '.scss', '.json', '.yaml', '.yml', 
                      '.md', '.java', '.cs', '.cpp', '.c', '.h', '.hpp', '.go', '.rs', '.php',
                      '.rb', '.sql', '.sh', '.txt'}
IGNORED_DIRS = {'.venv', '.git', '__pycache__', 'node_modules', 'bin', 'obj'}

# --- B·∫ÆT ƒê·∫¶U TH√äM M·ªöI ---
def print_streamed_markdown(console: Console, text: str, speed: float = 0.005):
    """
    In m·ªôt chu·ªói Markdown ra console v·ªõi hi·ªáu ·ª©ng streaming t·ª´ng t·ª´.
    H√†m n√†y gi√∫p c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng m√† kh√¥ng c·∫ßn thay ƒë·ªïi logic API.
    """
    if not text.strip():
        return

    buffer = ""
    # In t·ª´ng k√Ω t·ª± ƒë·ªÉ c√≥ hi·ªáu ·ª©ng m∆∞·ª£t m√†
    for char in text:
        buffer += char
        # Ch·ªâ render l·∫°i Markdown sau khi g·∫∑p kho·∫£ng tr·∫Øng ho·∫∑c d√≤ng m·ªõi ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t
        if char.isspace() or char in ['.', ',', '!', '?', ':', ';']:
            console.print(Markdown(buffer), end="")
            # D√πng \r ƒë·ªÉ ƒë∆∞a con tr·ªè v·ªÅ ƒë·∫ßu d√≤ng, chu·∫©n b·ªã ghi ƒë√®
            # Tuy nhi√™n, Rich x·ª≠ l√Ω vi·ªác n√†y t·ªët h∆°n, ta ch·ªâ c·∫ßn in ch·ªìng l√™n
            # V√¨ v·∫≠y, ch√∫ng ta s·∫Ω x√≥a d√≤ng hi·ªán t·∫°i tr∆∞·ªõc khi in buffer m·ªõi
            # Rich kh√¥ng c√≥ c√°ch tr·ª±c ti·∫øp ƒë·ªÉ "x√≥a v√† v·∫Ω l·∫°i", 
            # vi·ªác in li√™n t·ª•c v·ªõi end="" l√† c√°ch ti·∫øp c·∫≠n t·ªët nh·∫•t c·ªßa n√≥.
            # Trong tr∆∞·ªùng h·ª£p n√†y, ch√∫ng ta s·∫Ω ƒë·ªÉ Rich t·ª± qu·∫£n l√Ω vi·ªác render.
            # V·ªõi Rich, c√°ch t·ªët nh·∫•t l√† build buffer v√† in ra m·ªôt l·∫ßn.
            # ƒê·ªÉ t·∫°o hi·ªáu ·ª©ng, ch√∫ng ta s·∫Ω d√πng c√°ch th·ªß c√¥ng h∆°n.
            
    # In ph·∫ßn c√≤n l·∫°i c·ªßa buffer
    console.print(Markdown(buffer))

    # C√°ch ti·∫øp c·∫≠n th·ª© hai, ƒë∆°n gi·∫£n h∆°n v√† hi·ªáu qu·∫£ v·ªõi Rich
    # rendered_text = ""
    # for word in text.split(' '):
    #     rendered_text += word + " "
    #     console.clear() # C√≥ th·ªÉ g√¢y nh·∫•p nh√°y
    #     console.print(Markdown(rendered_text))
    #     time.sleep(speed)
# --- K·∫æT TH√öC TH√äM M·ªöI ---


def get_directory_context() -> str:
    """ƒê·ªçc t·∫•t c·∫£ file h·ª£p l·ªá trong th∆∞ m·ª•c hi·ªán t·∫°i v√† tr·∫£ v·ªÅ n·ªôi dung."""
    context_str = ""
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in IGNORED_DIRS]
        
        for file in files:
            if any(file.endswith(ext) for ext in ALLOWED_EXTENSIONS):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        context_str += f"--- START OF FILE: {file_path} ---\n\n"
                        context_str += f.read()
                        context_str += f"\n\n--- END OF FILE: {file_path} ---\n\n"
                except Exception as e:
                    context_str += f"--- COULD NOT READ FILE: {file_path} (Error: {e}) ---\n\n"
    return context_str

def execute_suggested_commands(text: str, console: Console):
    """T√¨m, h·ªèi v√† th·ª±c thi c√°c l·ªánh shell ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t m·ªôt c√°ch linh ho·∫°t."""
    command_blocks = re.findall(r"```(bash|shell|sh)\n(.*?)\n```", text, re.DOTALL)
    
    if not command_blocks:
        return

    execute_all = False
    for _, command in command_blocks:
        command = command.strip()
        
        if not execute_all:
            console.print(f"\n[bold yellow]AI ƒë√£ ƒë·ªÅ xu·∫•t m·ªôt l·ªánh:[/bold yellow]")
            console.print(f"[cyan on default]{command}[/cyan on default]")
            choice = console.input("Th·ª±c thi? [y]es/[n]o/[a]ll/[q]uit: ").lower()

            if choice == 'q':
                console.print("[yellow]ƒê√£ h·ªßy th·ª±c thi cho t·∫•t c·∫£ c√°c l·ªánh c√≤n l·∫°i.[/yellow]")
                break
            elif choice == 'a':
                execute_all = True
            elif choice != 'y':
                console.print("[yellow]ƒê√£ b·ªè qua l·ªánh.[/yellow]")
                continue
        
        try:
            console.print(f"[italic green]ƒêang th·ª±c thi...[/italic green]")
            process = subprocess.Popen(
                command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8'
            )
            for line in process.stdout:
                console.print(f"[dim]{line.strip()}[/dim]")
            for line in process.stderr:
                console.print(f"[bold red]L·ªói:[/bold red] [dim]{line.strip()}[/dim]")
            process.wait()
            console.print(f"[bold green]‚úÖ Th·ª±c thi ho√†n t·∫•t.[/bold green]")
        except Exception as e:
            console.print(f"[bold red]L·ªói khi th·ª±c thi l·ªánh: {e}[/bold red]")
            
def sanitize_filename(name: str) -> str:
    """Chuy·ªÉn ƒë·ªïi m·ªôt chu·ªói b·∫•t k·ª≥ th√†nh m·ªôt t√™n file an to√†n."""
    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng, b·ªè d·∫•u
    sanitized_name = unidecode(name).lower()
    # Thay th·∫ø c√°c k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ, s·ªë, g·∫°ch d∆∞·ªõi b·∫±ng g·∫°ch d∆∞·ªõi
    sanitized_name = re.sub(r'[^\w\s-]', '', sanitized_name).strip()
    sanitized_name = re.sub(r'[-\s]+', '_', sanitized_name)
    return sanitized_name

================================================================================
